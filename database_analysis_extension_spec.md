# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–å‹åˆ†ææ©Ÿèƒ½ æ‹¡å¼µä»•æ§˜æ›¸

## 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ãƒã‚°ã®èª²é¡Œåˆ†æ

### 1.1 å…¸å‹çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ç™ºç”Ÿã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ãƒã‚°ã®å…¸å‹ä¾‹ã‚’åˆ†é¡ã„ãŸã—ã¾ã—ãŸ:

| ãƒã‚°ã‚«ãƒ†ã‚´ãƒª | ç™ºç”Ÿé »åº¦ | å½±éŸ¿åº¦ | æ¤œå‡ºé›£æ˜“åº¦ |
|------------|---------|--------|-----------|
| N+1ã‚¯ã‚¨ãƒªå•é¡Œ | é«˜ | ä¸­ | ä¸­ |
| ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«æ¯æ¸‡ | ä¸­ | é«˜ | é«˜ |
| ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã®èª¤ã‚Š | é«˜ | é«˜ | é«˜ |
| ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸è¶³ã«ã‚ˆã‚‹ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒª | é«˜ | ä¸­ | ä¸­ |
| ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆ (åˆ†æ•£ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³) | ä¸­ | é«˜ | é«˜ |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒæœŸã®å•é¡Œ (Redis) | ä¸­ | ä¸­ | é«˜ |
| Cassandraæ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®èª¤è¨­å®š | ä½ | é«˜ | é«˜ |
| Elasticsearchæ¤œç´¢æ¡ä»¶ã®èª¤ã‚Š | ä¸­ | ä¸­ | ä½ |
| ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ | ä½ | é«˜ | é«˜ |
| ãƒªã‚½ãƒ¼ã‚¹ãƒªãƒ¼ã‚¯ (æœªã‚¯ãƒ­ãƒ¼ã‚ºæ¥ç¶š) | ä¸­ | é«˜ | ä¸­ |

### 1.2 å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç‰¹æ€§

#### Cassandra
- **ç‰¹æ€§**: åˆ†æ•£NoSQLã€APå‹(å¯ç”¨æ€§ãƒ»åˆ†æ–­è€æ€§é‡è¦–)
- **ä¸»ãªãƒã‚°**: æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®èª¤è¨­å®šã€Partition keyã®è¨­è¨ˆãƒŸã‚¹ã€Tombstoneã®è“„ç©
- **æ¤œå‡ºå¯¾è±¡**: CQLæ–‡ã€æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã€ãƒãƒƒãƒå‡¦ç†ã€éåŒæœŸå‡¦ç†

#### Elasticsearch
- **ç‰¹æ€§**: åˆ†æ•£æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã€å…¨æ–‡æ¤œç´¢
- **ä¸»ãªãƒã‚°**: è¤‡é›‘ãªã‚¯ã‚¨ãƒªã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆã€ã‚·ãƒ£ãƒ¼ãƒ‰ä¸å‡è¡¡
- **æ¤œå‡ºå¯¾è±¡**: Search APIå‘¼ã³å‡ºã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ“ä½œã€ãƒãƒ«ã‚¯å‡¦ç†

#### Redis
- **ç‰¹æ€§**: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€Key-Value Store
- **ä¸»ãªãƒã‚°**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–æ¼ã‚Œã€TTLè¨­å®šãƒŸã‚¹ã€ãƒ¡ãƒ¢ãƒªæ¯æ¸‡
- **æ¤œå‡ºå¯¾è±¡**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ“ä½œã€ã‚­ãƒ¼å‘½åè¦å‰‡ã€Pub/Sub

#### MySQL / SQL Server
- **ç‰¹æ€§**: RDBMSã€ACIDä¿è¨¼
- **ä¸»ãªãƒã‚°**: SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ã€ãƒ­ãƒƒã‚¯ç«¶åˆ
- **æ¤œå‡ºå¯¾è±¡**: SQLæ–‡ã€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã€æ¥ç¶šç®¡ç†

---

## 2. æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆ

### 2.1 æ–°è¦ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—

#### 2.1.1 DatabaseQueryãƒãƒ¼ãƒ‰
```cypher
(:DatabaseQuery {
  id: "query_uuid",
  queryText: "SELECT * FROM users WHERE email = ?",
  queryType: "SELECT|INSERT|UPDATE|DELETE|CQL|DSL",
  database: "mysql|sqlserver|cassandra|elasticsearch|redis",
  isPrepared: true,
  hasParameters: true,
  complexity: 5.2,  // ã‚¯ã‚¨ãƒªè¤‡é›‘åº¦
  estimatedRows: 1000,  // æƒ³å®šè¿”å´è¡Œæ•°
  hasIndex: true,  // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨æœ‰ç„¡
  executionTime: 0.025,  // å®Ÿè¡Œæ™‚é–“(ç§’) - ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‹ã‚‰
  lineNumber: 145
})
```

#### 2.1.2 DatabaseEntityãƒãƒ¼ãƒ‰ (ãƒ†ãƒ¼ãƒ–ãƒ«/ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³)
```cypher
(:DatabaseEntity {
  id: "entity_uuid",
  name: "users",
  type: "table|collection|index|cache_key",
  database: "mysql",
  schema: "public",
  estimatedSize: 1000000,  // ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
  hasIndex: true,
  primaryKey: ["id"],
  foreignKeys: ["company_id"],
  accessFrequency: "high|medium|low"
})
```

#### 2.1.3 TransactionBoundaryãƒãƒ¼ãƒ‰
```cypher
(:TransactionBoundary {
  id: "tx_uuid",
  type: "begin|commit|rollback",
  isolationLevel: "READ_COMMITTED|SERIALIZABLE|...",
  isDistributed: false,
  lineNumber: 89,
  methodId: "com.example.Service.updateUser"
})
```

#### 2.1.4 ConnectionPoolãƒãƒ¼ãƒ‰
```cypher
(:ConnectionPool {
  id: "pool_uuid",
  database: "mysql",
  maxConnections: 20,
  minConnections: 5,
  timeout: 30000,
  configFile: "/config/database.yml",
  usageLocations: ["ServiceA.java", "ServiceB.java"]
})
```

#### 2.1.5 CacheOperationãƒãƒ¼ãƒ‰ (Redisç‰¹åŒ–)
```cypher
(:CacheOperation {
  id: "cache_op_uuid",
  operation: "get|set|delete|expire",
  keyPattern: "user:*:profile",
  ttl: 3600,
  isDistributed: true,
  lineNumber: 67
})
```

#### 2.1.6 DataAccessLayerãƒãƒ¼ãƒ‰ (DAO/Repository)
```cypher
(:DataAccessLayer {
  id: "dao_uuid",
  name: "UserRepository",
  type: "DAO|Repository|Mapper",
  framework: "MyBatis|Hibernate|Spring Data|Custom",
  database: "mysql",
  entityName: "User",
  methods: ["findById", "save", "update", "delete"]
})
```

### 2.2 æ–°è¦é–¢ä¿‚æ€§ã‚¿ã‚¤ãƒ—

#### 2.2.1 EXECUTES_QUERY
```cypher
(:Method)-[:EXECUTES_QUERY {
  frequency: 5,  // é™çš„è§£æã§ã®å‡ºç¾å›æ•°
  isConditional: false,
  isInLoop: true,  // ãƒ«ãƒ¼ãƒ—å†…ã§ã®å®Ÿè¡Œ
  isAsync: false,
  lineNumber: 145
}]->(:DatabaseQuery)
```

#### 2.2.2 ACCESSES_ENTITY
```cypher
(:DatabaseQuery)-[:ACCESSES_ENTITY {
  operation: "read|write|readwrite",
  isIndexed: true,
  estimatedCost: 1.5  // ã‚¯ã‚¨ãƒªã‚³ã‚¹ãƒˆ
}]->(:DatabaseEntity)
```

#### 2.2.3 WITHIN_TRANSACTION
```cypher
(:DatabaseQuery)-[:WITHIN_TRANSACTION {
  position: 2,  // ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§ã®é †åº
  canRollback: true
}]->(:TransactionBoundary)
```

#### 2.2.4 USES_CONNECTION_POOL
```cypher
(:DataAccessLayer)-[:USES_CONNECTION_POOL {
  isDirect: false,
  framework: "Spring"
}]->(:ConnectionPool)
```

#### 2.2.5 INVALIDATES_CACHE
```cypher
(:Method)-[:INVALIDATES_CACHE {
  strategy: "explicit|implicit|pattern",
  lineNumber: 89
}]->(:CacheOperation)
```

#### 2.2.6 DEPENDS_ON_CACHE
```cypher
(:Method)-[:DEPENDS_ON_CACHE {
  isCritical: true,  // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚ã®å½±éŸ¿
  fallbackExists: true,
  lineNumber: 45
}]->(:CacheOperation)
```

#### 2.2.7 CROSS_DATABASE_OPERATION
```cypher
(:Method)-[:CROSS_DATABASE_OPERATION {
  databases: ["mysql", "cassandra"],
  hasDistributedTx: false,  // åˆ†æ•£ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœ‰ç„¡
  consistencyRisk: "high|medium|low"
}]->(:Method)
```

---

## 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–å‹ãƒ‘ãƒ¼ã‚µãƒ¼æ‹¡å¼µ

### 3.1 SQL/CQL/DSLè§£æã‚¨ãƒ³ã‚¸ãƒ³

#### 3.1.1 SQLè§£æ (MySQL/SQL Server)
```python
class SQLAnalyzer:
    def __init__(self):
        self.parser = sqlparse.Parser()
        
    def analyze_sql_in_code(self, file_path: str) -> List[DatabaseQuery]:
        """
        ã‚³ãƒ¼ãƒ‰å†…ã®SQLæ–‡ã‚’æŠ½å‡ºãƒ»è§£æ
        """
        queries = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«å†…ã®SQL
        sql_patterns = [
            r'\"(SELECT|INSERT|UPDATE|DELETE).*?\"',
            r'\'(SELECT|INSERT|UPDATE|DELETE).*?\'',
        ]
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³2: MyBatis XMLãƒãƒƒãƒ”ãƒ³ã‚°
        mybatis_queries = self._parse_mybatis_xml(file_path)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³3: Hibernate HQL
        hql_queries = self._parse_hql(file_path)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³4: Spring Data Query annotations
        spring_queries = self._parse_spring_data_queries(file_path)
        
        for sql in all_queries:
            query_info = self._analyze_single_query(sql)
            queries.append(query_info)
            
        return queries
    
    def _analyze_single_query(self, sql: str) -> DatabaseQuery:
        """
        å€‹åˆ¥ã®SQLã‚’è©³ç´°ã«è§£æ
        """
        parsed = sqlparse.parse(sql)[0]
        
        # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
        query_type = self._get_query_type(parsed)
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æŠ½å‡º
        tables = self._extract_tables(parsed)
        
        # WHEREå¥ã®åˆ†æ
        where_clauses = self._analyze_where_clause(parsed)
        
        # JOINã®æ¤œå‡º
        joins = self._extract_joins(parsed)
        
        # ã‚µãƒ–ã‚¯ã‚¨ãƒªã®æ¤œå‡º
        subqueries = self._detect_subqueries(parsed)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ã®æ¨å®š
        has_index = self._estimate_index_usage(tables, where_clauses)
        
        # N+1å•é¡Œã®å¯èƒ½æ€§
        n_plus_one_risk = self._detect_n_plus_one_pattern(sql, context)
        
        return DatabaseQuery(
            queryText=sql,
            queryType=query_type,
            tables=tables,
            hasIndex=has_index,
            complexity=self._calculate_complexity(parsed),
            nPlusOneRisk=n_plus_one_risk
        )
    
    def _detect_n_plus_one_pattern(self, sql: str, context: CodeContext) -> bool:
        """
        N+1å•é¡Œã®æ¤œå‡º
        """
        # ãƒ«ãƒ¼ãƒ—å†…ã§ã®SELECTã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚’æ¤œå‡º
        if context.is_in_loop and sql.strip().upper().startswith('SELECT'):
            # å¤–éƒ¨ã‚­ãƒ¼ã«å¯¾ã™ã‚‹WHEREå¥ã‚’æŒã¤
            if self._has_foreign_key_condition(sql):
                return True
        return False
```

#### 3.1.2 Cassandra CQLè§£æ
```python
class CassandraAnalyzer:
    def analyze_cql(self, cql: str, context: CodeContext) -> CassandraQuery:
        """
        CQLå›ºæœ‰ã®å•é¡Œã‚’æ¤œå‡º
        """
        # Consistency Levelã®å–å¾—
        consistency_level = self._extract_consistency_level(context)
        
        # Partition Keyã®ä½¿ç”¨ç¢ºèª
        uses_partition_key = self._check_partition_key_usage(cql)
        
        # ALLOW FILTERINGã®æ¤œå‡º (ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³)
        has_allow_filtering = 'ALLOW FILTERING' in cql.upper()
        
        # ãƒãƒƒãƒå‡¦ç†ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        is_large_batch = self._check_batch_size(cql, context)
        
        # Tombstoneãƒªã‚¹ã‚¯
        tombstone_risk = self._assess_tombstone_risk(cql)
        
        return CassandraQuery(
            cql=cql,
            consistencyLevel=consistency_level,
            usesPartitionKey=uses_partition_key,
            hasAllowFiltering=has_allow_filtering,
            isLargeBatch=is_large_batch,
            tombstoneRisk=tombstone_risk
        )
    
    def _check_partition_key_usage(self, cql: str) -> bool:
        """
        WHEREå¥ã§Partition KeyãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        """
        # ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ã®ç…§åˆãŒå¿…è¦
        # ã“ã“ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
        where_clause = self._extract_where_clause(cql)
        # Partition Keyå®šç¾©ã¨ç…§åˆ
        return True  # å®Ÿè£…ã¯è¤‡é›‘
```

#### 3.1.3 Elasticsearch DSLè§£æ
```python
class ElasticsearchAnalyzer:
    def analyze_es_query(self, query_dsl: dict, context: CodeContext) -> ESQuery:
        """
        Elasticsearch Query DSLã‚’è§£æ
        """
        # ã‚¯ã‚¨ãƒªã®ç¨®é¡
        query_type = self._detect_query_type(query_dsl)
        
        # è¤‡é›‘åº¦ã®è¨ˆç®—
        complexity = self._calculate_es_complexity(query_dsl)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° vs ã‚¯ã‚¨ãƒªãƒ³ã‚°
        uses_filter = 'filter' in json.dumps(query_dsl)
        
        # ã‚¢ã‚°ãƒªã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
        has_aggregation = 'aggs' in query_dsl
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½¿ç”¨ (ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ‡¸å¿µ)
        uses_script = self._detect_script_usage(query_dsl)
        
        # ãƒ¯ã‚¤ãƒ«ãƒ‰ã‚«ãƒ¼ãƒ‰ã‚¯ã‚¨ãƒª (ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³)
        has_wildcard = self._detect_wildcard_query(query_dsl)
        
        return ESQuery(
            queryDsl=query_dsl,
            queryType=query_type,
            complexity=complexity,
            usesScript=uses_script,
            hasWildcard=has_wildcard,
            performanceRisk=self._assess_performance_risk(query_dsl)
        )
```

#### 3.1.4 Redisæ“ä½œè§£æ
```python
class RedisAnalyzer:
    def analyze_redis_operations(self, file_path: str) -> List[CacheOperation]:
        """
        Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥æ“ä½œã‚’è§£æ
        """
        operations = []
        
        # Redisã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå‘¼ã³å‡ºã—ã‚’æ¤œå‡º
        redis_calls = self._find_redis_calls(file_path)
        
        for call in redis_calls:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
            key_pattern = self._extract_key_pattern(call)
            
            # TTLè¨­å®šã®æœ‰ç„¡
            has_ttl = self._check_ttl_setting(call)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã®è¿½è·¡
            invalidation_points = self._find_invalidation_points(key_pattern)
            
            # Cache-Aside vs Read/Write-Throughæ¤œå‡º
            cache_pattern = self._detect_cache_pattern(call)
            
            operations.append(CacheOperation(
                keyPattern=key_pattern,
                hasTTL=has_ttl,
                cachePattern=cache_pattern,
                invalidationPoints=invalidation_points
            ))
        
        return operations
    
    def _find_invalidation_points(self, key_pattern: str) -> List[str]:
        """
        ç‰¹å®šã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç„¡åŠ¹åŒ–ã™ã‚‹ç®‡æ‰€ã‚’å…¨ã¦ç‰¹å®š
        """
        # ã‚°ãƒ©ãƒ•DBã‚¯ã‚¨ãƒªã§é–¢é€£ã™ã‚‹å‰Šé™¤æ“ä½œã‚’æ¤œç´¢
        query = """
        MATCH (cache:CacheOperation {keyPattern: $pattern, operation: 'delete'})
        MATCH (method:Method)-[:EXECUTES_CACHE_OP]->(cache)
        RETURN method.name as methodName, method.id as methodId
        """
        return neo4j_driver.execute_query(query, pattern=key_pattern)
```

### 3.2 ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã®è‡ªå‹•æ¤œå‡º

```python
class TransactionAnalyzer:
    def analyze_transactions(self, file_path: str) -> List[TransactionBoundary]:
        """
        ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã‚’è‡ªå‹•æ¤œå‡º
        """
        transactions = []
        
        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®æ¤œå‡º (Spring @Transactional)
        spring_tx = self._detect_spring_transactional(file_path)
        
        # ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³
        programmatic_tx = self._detect_programmatic_tx(file_path)
        
        # ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ã‚¯ã‚¨ãƒªã‚’ç‰¹å®š
        for tx in all_transactions:
            queries = self._find_queries_in_transaction(tx)
            
            # åˆ†æ•£ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®æ¤œå‡º
            is_distributed = self._check_distributed_tx(queries)
            
            # ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ãƒªã‚¹ã‚¯ã®è©•ä¾¡
            deadlock_risk = self._assess_deadlock_risk(queries)
            
            transactions.append(TransactionBoundary(
                isolationLevel=tx.isolation,
                isDistributed=is_distributed,
                deadlockRisk=deadlock_risk,
                queries=queries
            ))
        
        return transactions
    
    def _assess_deadlock_risk(self, queries: List[DatabaseQuery]) -> str:
        """
        ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡
        """
        # è¤‡æ•°ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®æ›¸ãè¾¼ã¿
        write_tables = [q.tables for q in queries if q.is_write()]
        
        # ãƒ­ãƒƒã‚¯é †åºã®ä¸æ•´åˆã‚’æ¤œå‡º
        if len(write_tables) > 1:
            # ä»–ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã¨æ¯”è¼ƒ
            return "high"
        
        return "low"
```

---

## 4. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–å‹åˆ†æã‚¯ã‚¨ãƒª

### 4.1 N+1å•é¡Œã®æ¤œå‡º

```cypher
// N+1å•é¡Œã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’æ¤œå‡º
MATCH (method:Method)-[exec:EXECUTES_QUERY]->(query:DatabaseQuery)
WHERE exec.isInLoop = true 
  AND query.queryType = 'SELECT'
  AND query.hasParameters = true
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
RETURN file.path, 
       class.name, 
       method.name,
       query.queryText,
       exec.frequency as loopExecutionCount,
       'N+1 Problem Risk' as issue
ORDER BY loopExecutionCount DESC
```

### 4.2 ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç†ã®DBæ“ä½œ

```cypher
// ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¤–ã§ã®DBæ›¸ãè¾¼ã¿æ“ä½œ
MATCH (method:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
WHERE query.queryType IN ['INSERT', 'UPDATE', 'DELETE']
  AND NOT (query)-[:WITHIN_TRANSACTION]->(:TransactionBoundary)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
RETURN file.path,
       class.name,
       method.name,
       query.queryText,
       'Missing Transaction Boundary' as issue
```

### 4.3 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–æ¼ã‚Œã®æ¤œå‡º

```cypher
// ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã™ã‚‹ãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã—ãªã„ãƒ¡ã‚½ãƒƒãƒ‰
MATCH (updateMethod:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
WHERE query.queryType IN ['INSERT', 'UPDATE', 'DELETE']
MATCH (query)-[:ACCESSES_ENTITY]->(entity:DatabaseEntity)
MATCH (readMethod:Method)-[:DEPENDS_ON_CACHE]->(cache:CacheOperation)
WHERE cache.keyPattern CONTAINS entity.name
  AND NOT (updateMethod)-[:INVALIDATES_CACHE]->()
RETURN updateMethod.name as updatingMethod,
       entity.name as affectedEntity,
       readMethod.name as cachedReadMethod,
       'Cache Invalidation Missing' as issue
```

### 4.4 ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒªãƒ¼ã‚¯ã®æ¤œå‡º

```cypher
// ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã‚’é–‹ããŒæ˜ç¤ºçš„ã«ã‚¯ãƒ­ãƒ¼ã‚ºã—ãªã„ãƒ¡ã‚½ãƒƒãƒ‰
MATCH (method:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
MATCH (method)-[:USES_CONNECTION_POOL]->(pool:ConnectionPool)
WHERE NOT EXISTS {
  MATCH (method)-[:CONTAINS]->(stmt)
  WHERE stmt.type = 'try-with-resources' 
     OR stmt.type = 'finally-close'
}
RETURN method.name,
       pool.database,
       'Potential Connection Leak' as issue
```

### 4.5 ã‚¯ãƒ­ã‚¹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒªã‚¹ã‚¯

```cypher
// è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ“ä½œã™ã‚‹ãŒåˆ†æ•£ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªä½¿ç”¨
MATCH (method:Method)-[:EXECUTES_QUERY]->(q1:DatabaseQuery)
MATCH (method)-[:EXECUTES_QUERY]->(q2:DatabaseQuery)
WHERE q1.database <> q2.database
  AND q1.queryType IN ['INSERT', 'UPDATE', 'DELETE']
  AND q2.queryType IN ['INSERT', 'UPDATE', 'DELETE']
  AND NOT (method)-[:CROSS_DATABASE_OPERATION {hasDistributedTx: true}]->()
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
RETURN file.path,
       method.name,
       collect(DISTINCT q1.database) as databases,
       'Cross-Database Consistency Risk' as issue
```

### 4.6 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸è¶³ã®æ¤œå‡º

```cypher
// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„é«˜é »åº¦ã‚¯ã‚¨ãƒª
MATCH (method:Method)-[exec:EXECUTES_QUERY]->(query:DatabaseQuery)
WHERE query.hasIndex = false
  AND exec.frequency > 10
  AND query.estimatedRows > 1000
MATCH (query)-[:ACCESSES_ENTITY]->(entity:DatabaseEntity)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
RETURN file.path,
       method.name,
       query.queryText,
       entity.name as table,
       query.estimatedRows as rowCount,
       'Missing Index - Performance Issue' as issue
ORDER BY query.estimatedRows DESC
```

### 4.7 Cassandraæ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®ä¸æ•´åˆ

```cypher
// èª­ã¿è¾¼ã¿ã¨æ›¸ãè¾¼ã¿ã§æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ãŒåˆã‚ãªã„
MATCH (readMethod:Method)-[:EXECUTES_QUERY]->(readQuery:DatabaseQuery)
WHERE readQuery.database = 'cassandra'
  AND readQuery.queryType = 'SELECT'
MATCH (writeMethod:Method)-[:EXECUTES_QUERY]->(writeQuery:DatabaseQuery)
WHERE writeQuery.database = 'cassandra'
  AND writeQuery.queryType IN ['INSERT', 'UPDATE']
MATCH (readQuery)-[:ACCESSES_ENTITY]->(entity:DatabaseEntity)
MATCH (writeQuery)-[:ACCESSES_ENTITY]->(entity)
WHERE readQuery.consistencyLevel <> writeQuery.consistencyLevel
RETURN readMethod.name,
       writeMethod.name,
       entity.name,
       readQuery.consistencyLevel as readCL,
       writeQuery.consistencyLevel as writeCL,
       'Consistency Level Mismatch' as issue
```

### 4.8 Elasticsearché‡ã„ã‚¯ã‚¨ãƒªã®æ¤œå‡º

```cypher
// è¤‡é›‘ã™ãã‚‹Elasticsearchã‚¯ã‚¨ãƒª
MATCH (method:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
WHERE query.database = 'elasticsearch'
  AND query.complexity > 7.0
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
RETURN file.path,
       method.name,
       query.complexity,
       query.usesScript as hasScript,
       query.hasWildcard as hasWildcard,
       'Complex Elasticsearch Query' as issue
ORDER BY query.complexity DESC
```

---

## 5. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚°å½±éŸ¿ç¯„å›²åˆ†æAPI

### 5.1 æ–°è¦APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

```python
from fastapi import FastAPI, Query
from typing import List, Optional

app = FastAPI()

@app.post("/api/v1/database/analyze/impact")
async def analyze_database_impact(
    query_id: str,
    depth: int = 3
):
    """
    ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®å¤‰æ›´ãŒåŠã¼ã™å½±éŸ¿ã‚’åˆ†æ
    """
    cypher_query = """
    MATCH (query:DatabaseQuery {id: $queryId})
    MATCH (query)-[:ACCESSES_ENTITY]->(entity:DatabaseEntity)
    
    // ã“ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ä»–ã®ã‚¯ã‚¨ãƒª
    MATCH (otherQuery:DatabaseQuery)-[:ACCESSES_ENTITY]->(entity)
    MATCH (method:Method)-[:EXECUTES_QUERY]->(otherQuery)
    MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¾å­˜é–¢ä¿‚
    OPTIONAL MATCH (method)-[:DEPENDS_ON_CACHE]->(cache:CacheOperation)
    WHERE cache.keyPattern CONTAINS entity.name
    
    RETURN DISTINCT 
        file.path,
        class.name,
        method.name,
        otherQuery.queryText,
        collect(cache.keyPattern) as affectedCaches
    """
    
    results = neo4j_driver.execute_query(cypher_query, queryId=query_id)
    
    return {
        "query_id": query_id,
        "affected_methods": results,
        "cache_invalidation_required": [r['affectedCaches'] for r in results if r['affectedCaches']]
    }

@app.get("/api/v1/database/detect/n-plus-one")
async def detect_n_plus_one_problems(
    database: Optional[str] = None,
    severity: str = Query("all", regex="^(all|high|medium|low)$")
):
    """
    N+1å•é¡Œã‚’æ¤œå‡º
    """
    cypher_query = """
    MATCH (method:Method)-[exec:EXECUTES_QUERY]->(query:DatabaseQuery)
    WHERE exec.isInLoop = true 
      AND query.queryType = 'SELECT'
      AND ($database IS NULL OR query.database = $database)
    MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
    
    // ãƒ«ãƒ¼ãƒ—ã®æ·±ã•ã‚’è¨ˆç®—
    OPTIONAL MATCH loopPath = (method)-[:CALLS*1..3]->(loopMethod:Method)
    WHERE loopMethod.name CONTAINS 'forEach' OR loopMethod.name CONTAINS 'map'
    
    RETURN file.path,
           class.name,
           method.name,
           query.queryText,
           exec.frequency as executionCount,
           length(loopPath) as loopDepth,
           CASE 
             WHEN exec.frequency > 100 THEN 'high'
             WHEN exec.frequency > 50 THEN 'medium'
             ELSE 'low'
           END as severity
    ORDER BY executionCount DESC
    """
    
    results = neo4j_driver.execute_query(cypher_query, database=database)
    
    if severity != "all":
        results = [r for r in results if r['severity'] == severity]
    
    return {
        "n_plus_one_issues": results,
        "total_count": len(results),
        "recommendations": [
            "Use eager loading / JOIN FETCH",
            "Implement batch fetching",
            "Consider caching frequently accessed data"
        ]
    }

@app.get("/api/v1/database/detect/missing-transactions")
async def detect_missing_transactions(database: Optional[str] = None):
    """
    ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•ŒãŒæ¬ ã‘ã¦ã„ã‚‹DBæ›¸ãè¾¼ã¿æ“ä½œã‚’æ¤œå‡º
    """
    cypher_query = """
    MATCH (method:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
    WHERE query.queryType IN ['INSERT', 'UPDATE', 'DELETE']
      AND NOT (query)-[:WITHIN_TRANSACTION]->(:TransactionBoundary)
      AND ($database IS NULL OR query.database = $database)
    MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
    RETURN file.path,
           class.name,
           method.name,
           query.queryText,
           query.database
    """
    
    results = neo4j_driver.execute_query(cypher_query, database=database)
    
    return {
        "missing_transactions": results,
        "total_count": len(results),
        "risk_level": "high" if len(results) > 0 else "low"
    }

@app.get("/api/v1/database/detect/cache-inconsistency")
async def detect_cache_inconsistency():
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–æ¼ã‚Œã‚’æ¤œå‡º
    """
    cypher_query = """
    MATCH (updateMethod:Method)-[:EXECUTES_QUERY]->(query:DatabaseQuery)
    WHERE query.queryType IN ['INSERT', 'UPDATE', 'DELETE']
    MATCH (query)-[:ACCESSES_ENTITY]->(entity:DatabaseEntity)
    
    // ã“ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã„ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
    MATCH (readMethod:Method)-[:DEPENDS_ON_CACHE]->(cache:CacheOperation)
    WHERE cache.keyPattern CONTAINS entity.name
    
    // ç„¡åŠ¹åŒ–å‡¦ç†ãŒãªã„
    WHERE NOT (updateMethod)-[:INVALIDATES_CACHE]->()
    
    MATCH (updateMethod)<-[:CONTAINS]-(updateClass:Class)<-[:CONTAINS]-(updateFile:File)
    MATCH (readMethod)<-[:CONTAINS]-(readClass:Class)<-[:CONTAINS]-(readFile:File)
    
    RETURN updateFile.path as updateLocation,
           updateMethod.name as updateMethod,
           entity.name as affectedEntity,
           readFile.path as cachedLocation,
           readMethod.name as cachedMethod,
           cache.keyPattern as cacheKey
    """
    
    results = neo4j_driver.execute_query(cypher_query)
    
    return {
        "cache_inconsistencies": results,
        "total_count": len(results),
        "recommendations": [
            "Add cache invalidation after data modification",
            "Use cache-aside pattern consistently",
            "Consider event-driven cache invalidation"
        ]
    }

@app.get("/api/v1/database/analyze/connection-usage")
async def analyze_connection_pool_usage():
    """
    ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ã®ä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ
    """
    cypher_query = """
    MATCH (pool:ConnectionPool)
    MATCH (dal:DataAccessLayer)-[:USES_CONNECTION_POOL]->(pool)
    MATCH (method:Method)-[:CALLS]->(dalMethod:Method)
    WHERE dalMethod.name IN dal.methods
    
    WITH pool, 
         count(DISTINCT method) as usageCount,
         collect(DISTINCT method.name) as usageMethods
    
    RETURN pool.database,
           pool.maxConnections,
           usageCount,
           CASE 
             WHEN usageCount > pool.maxConnections * 0.8 THEN 'high'
             WHEN usageCount > pool.maxConnections * 0.5 THEN 'medium'
             ELSE 'low'
           END as utilizationLevel,
           usageMethods[0..10] as topMethods
    """
    
    results = neo4j_driver.execute_query(cypher_query)
    
    return {
        "connection_pools": results,
        "warnings": [
            r for r in results if r['utilizationLevel'] == 'high'
        ]
    }

@app.post("/api/v1/database/simulate/table-change")
async def simulate_table_change(
    table_name: str,
    database: str,
    change_type: str = Query(..., regex="^(add_column|remove_column|rename|delete)$")
):
    """
    ãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›´ã®å½±éŸ¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    cypher_query = """
    MATCH (entity:DatabaseEntity {name: $tableName, database: $database})
    
    // ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚¯ã‚¨ãƒª
    MATCH (query:DatabaseQuery)-[:ACCESSES_ENTITY]->(entity)
    MATCH (method:Method)-[:EXECUTES_QUERY]->(query)
    MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
    
    // ä¾å­˜ã™ã‚‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    OPTIONAL MATCH (cacheMethod:Method)-[:DEPENDS_ON_CACHE]->(cache:CacheOperation)
    WHERE cache.keyPattern CONTAINS entity.name
    
    // ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ä¸Šæµ
    OPTIONAL MATCH upstream = (caller:Method)-[:CALLS*1..3]->(method)
    
    RETURN file.path,
           class.name,
           method.name,
           query.queryText,
           query.queryType,
           collect(DISTINCT cache.keyPattern) as affectedCaches,
           count(DISTINCT caller) as upstreamCallers
    ORDER BY upstreamCallers DESC
    """
    
    results = neo4j_driver.execute_query(
        cypher_query, 
        tableName=table_name, 
        database=database
    )
    
    # å½±éŸ¿åº¦ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
    impact_score = sum([
        len(r['affectedCaches']) * 2 +  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å½±éŸ¿
        r['upstreamCallers']  # å‘¼ã³å‡ºã—å…ƒã®æ•°
        for r in results
    ])
    
    return {
        "table_name": table_name,
        "change_type": change_type,
        "affected_queries": len(results),
        "affected_files": len(set(r['file.path'] for r in results)),
        "impact_score": impact_score,
        "impact_level": "high" if impact_score > 50 else "medium" if impact_score > 20 else "low",
        "details": results,
        "recommendations": generate_change_recommendations(change_type, results)
    }

def generate_change_recommendations(change_type: str, affected: List[dict]) -> List[str]:
    """
    å¤‰æ›´ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    """
    recommendations = []
    
    if change_type == "add_column":
        recommendations.append("æ—¢å­˜ã®SELECT * ã¯å½±éŸ¿ã‚’å—ã‘ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ãŒã€ç¢ºèªãŒå¿…è¦ã§ã™")
        recommendations.append("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ›´æ–°ã—ã¦ãã ã•ã„")
    elif change_type == "remove_column":
        recommendations.append(f"{len(affected)} ç®‡æ‰€ã®ã‚¯ã‚¨ãƒªã§å‰Šé™¤ã•ã‚Œã‚‹ã‚«ãƒ©ãƒ ã‚’å‚ç…§ã—ã¦ã„ã¾ã™")
        recommendations.append("è©²å½“ã™ã‚‹ã‚¯ã‚¨ãƒªã‚’å…ˆã«ä¿®æ­£ã—ã¦ã‹ã‚‰ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    elif change_type == "rename":
        recommendations.append("ã™ã¹ã¦ã®ã‚¯ã‚¨ãƒªã¨ORMãƒãƒƒãƒ”ãƒ³ã‚°ã®æ›´æ–°ãŒå¿…è¦ã§ã™")
        recommendations.append("Blue-Green deploymentã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
    
    return recommendations

@app.get("/api/v1/database/detect/cross-database-issues")
async def detect_cross_database_issues():
    """
    è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¾ãŸãŒã‚‹æ•´åˆæ€§å•é¡Œã‚’æ¤œå‡º
    """
    cypher_query = """
    MATCH (method:Method)-[:EXECUTES_QUERY]->(q1:DatabaseQuery)
    MATCH (method)-[:EXECUTES_QUERY]->(q2:DatabaseQuery)
    WHERE q1.database <> q2.database
      AND (q1.queryType IN ['INSERT', 'UPDATE', 'DELETE'] 
           OR q2.queryType IN ['INSERT', 'UPDATE', 'DELETE'])
    MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)
    
    WITH method, file, class, 
         collect(DISTINCT q1.database) + collect(DISTINCT q2.database) as databases,
         count(*) as queryCount
    
    WHERE NOT (method)-[:CROSS_DATABASE_OPERATION {hasDistributedTx: true}]->()
    
    RETURN file.path,
           class.name,
           method.name,
           databases,
           queryCount,
           'Missing Distributed Transaction' as issue
    """
    
    results = neo4j_driver.execute_query(cypher_query)
    
    return {
        "cross_database_issues": results,
        "total_count": len(results),
        "risk_assessment": "HIGH - Data inconsistency possible",
        "recommendations": [
            "Implement distributed transaction (2PC or Saga pattern)",
            "Add compensating transactions for rollback",
            "Consider eventual consistency with event sourcing"
        ]
    }
```

---

## 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–å‹UIæ‹¡å¼µ

### 6.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```typescript
// DatabaseDashboard.tsx
interface DatabaseMetrics {
  database: string;
  queryCount: number;
  nPlusOneIssues: number;
  missingTransactions: number;
  cacheInconsistencies: number;
  connectionPoolUtilization: number;
}

export const DatabaseDashboard: React.FC = () => {
  const [metrics, setMetrics] = useState<DatabaseMetrics[]>([]);
  
  useEffect(() => {
    fetchDatabaseMetrics().then(setMetrics);
  }, []);
  
  return (
    <div className="database-dashboard">
      <h1>ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å“è³ªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</h1>
      
      {/* ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¥ã®å•é¡Œã‚µãƒãƒªãƒ¼ */}
      <div className="db-summary-grid">
        {metrics.map(db => (
          <Card key={db.database}>
            <h3>{db.database.toUpperCase()}</h3>
            <MetricBadge 
              label="N+1å•é¡Œ" 
              value={db.nPlusOneIssues} 
              severity={db.nPlusOneIssues > 10 ? 'high' : 'low'} 
            />
            <MetricBadge 
              label="ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç†" 
              value={db.missingTransactions}
              severity={db.missingTransactions > 0 ? 'high' : 'low'} 
            />
            <MetricBadge 
              label="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸æ•´åˆ" 
              value={db.cacheInconsistencies}
              severity={db.cacheInconsistencies > 5 ? 'medium' : 'low'} 
            />
            <ProgressBar 
              label="æ¥ç¶šãƒ—ãƒ¼ãƒ«ä½¿ç”¨ç‡" 
              value={db.connectionPoolUtilization} 
            />
          </Card>
        ))}
      </div>
      
      {/* ã‚¯ã‚¨ãƒªå®Ÿè¡Œé »åº¦ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— */}
      <QueryHeatmap />
      
      {/* ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–“ã®é–¢ä¿‚å›³ */}
      <CrossDatabaseDependencyGraph />
    </div>
  );
};
```

### 6.2 ã‚¯ã‚¨ãƒªå½±éŸ¿ç¯„å›²ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼

```typescript
// QueryImpactVisualizer.tsx
interface QueryImpactProps {
  queryId: string;
}

export const QueryImpactVisualizer: React.FC<QueryImpactProps> = ({ queryId }) => {
  const [impactData, setImpactData] = useState(null);
  
  useEffect(() => {
    fetch(`/api/v1/database/analyze/impact`, {
      method: 'POST',
      body: JSON.stringify({ query_id: queryId, depth: 5 })
    })
    .then(res => res.json())
    .then(setImpactData);
  }, [queryId]);
  
  if (!impactData) return <Loading />;
  
  return (
    <div className="query-impact-visualizer">
      <h2>ã‚¯ã‚¨ãƒªå½±éŸ¿ç¯„å›²åˆ†æ</h2>
      
      {/* ä¸­å¿ƒã«ã‚¯ã‚¨ãƒªã€æ”¾å°„çŠ¶ã«å½±éŸ¿ã‚’å—ã‘ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ */}
      <ForceDirectedGraph
        centerNode={{
          id: queryId,
          type: 'query',
          label: impactData.queryText
        }}
        affectedNodes={impactData.affected_methods.map(m => ({
          id: m.method_id,
          type: 'method',
          label: `${m.class_name}.${m.method_name}`,
          file: m.file_path
        }))}
      />
      
      {/* ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã®å¿…è¦æ€§ */}
      {impactData.cache_invalidation_required.length > 0 && (
        <Alert severity="warning">
          <AlertTitle>ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ãŒå¿…è¦</AlertTitle>
          <ul>
            {impactData.cache_invalidation_required.map(cache => (
              <li key={cache}>{cache}</li>
            ))}
          </ul>
        </Alert>
      )}
      
      {/* ãƒ†ãƒ¼ãƒ–ãƒ«å½±éŸ¿ç¯„å›² */}
      <TableImpactSummary data={impactData} />
    </div>
  );
};
```

### 6.3 N+1å•é¡Œã®å¯è¦–åŒ–

```typescript
// NPlusOneDetector.tsx
export const NPlusOneDetector: React.FC = () => {
  const [issues, setIssues] = useState([]);
  const [selectedDatabase, setSelectedDatabase] = useState<string | null>(null);
  
  useEffect(() => {
    fetch(`/api/v1/database/detect/n-plus-one?database=${selectedDatabase || 'all'}`)
      .then(res => res.json())
      .then(data => setIssues(data.n_plus_one_issues));
  }, [selectedDatabase]);
  
  return (
    <div className="n-plus-one-detector">
      <h2>N+1å•é¡Œæ¤œå‡º</h2>
      
      <DatabaseFilter onChange={setSelectedDatabase} />
      
      <DataGrid
        columns={[
          { field: 'file.path', headerName: 'ãƒ•ã‚¡ã‚¤ãƒ«', width: 300 },
          { field: 'method.name', headerName: 'ãƒ¡ã‚½ãƒƒãƒ‰', width: 200 },
          { field: 'executionCount', headerName: 'å®Ÿè¡Œå›æ•°', width: 100 },
          { field: 'severity', headerName: 'é‡è¦åº¦', width: 100,
            renderCell: (params) => (
              <Chip 
                label={params.value} 
                color={params.value === 'high' ? 'error' : 'warning'} 
              />
            )
          },
          { field: 'query.queryText', headerName: 'ã‚¯ã‚¨ãƒª', width: 400 }
        ]}
        rows={issues}
        onRowClick={(params) => navigateToCode(params.row['file.path'])}
      />
      
      <RecommendationPanel
        title="æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ–¹æ³•"
        items={[
          "Eager Loadingã¾ãŸã¯JOIN FETCHã‚’ä½¿ç”¨",
          "ãƒãƒƒãƒãƒ•ã‚§ãƒƒãƒãƒ³ã‚°ã®å®Ÿè£…",
          "é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"
        ]}
      />
    </div>
  );
};
```

---

## 7. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–å‹ã®è‡ªå‹•åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 7.1 CI/CDçµ±åˆ

```yaml
# .github/workflows/database-analysis.yml
name: Database Impact Analysis

on:
  pull_request:
    paths:
      - '**/*.java'
      - '**/*.ts'
      - '**/*.cs'
      - '**/*.go'
      - '**/mapper/**'  # MyBatis
      - '**/repositories/**'

jobs:
  analyze-database-changes:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v2
      
      - name: Run Database Analysis
        run: |
          docker-compose up -d neo4j
          python scripts/analyze_db_changes.py \
            --changed-files="${{ github.event.pull_request.changed_files }}"
      
      - name: Detect N+1 Problems
        id: n_plus_one
        run: |
          curl -X GET "http://localhost:8000/api/v1/database/detect/n-plus-one?severity=high" \
            -H "Authorization: Bearer ${{ secrets.API_TOKEN }}" \
            > n_plus_one_report.json
      
      - name: Check Transaction Boundaries
        id: transactions
        run: |
          curl -X GET "http://localhost:8000/api/v1/database/detect/missing-transactions" \
            > transaction_report.json
      
      - name: Comment on PR
        uses: actions/github-script@v5
        with:
          script: |
            const nPlusOne = require('./n_plus_one_report.json');
            const transactions = require('./transaction_report.json');
            
            let comment = '## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å½±éŸ¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n\n';
            
            if (nPlusOne.total_count > 0) {
              comment += `âš ï¸ **N+1å•é¡Œæ¤œå‡º**: ${nPlusOne.total_count}ä»¶\n\n`;
              comment += 'è©³ç´°:\n';
              nPlusOne.n_plus_one_issues.slice(0, 5).forEach(issue => {
                comment += `- \`${issue['file.path']}\`: ${issue['method.name']}\n`;
              });
            }
            
            if (transactions.total_count > 0) {
              comment += `\nğŸ”´ **ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç†**: ${transactions.total_count}ä»¶\n`;
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail if Critical Issues
        run: |
          if [ $(jq '.total_count' transaction_report.json) -gt 0 ]; then
            echo "âŒ Critical: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç†ã®DBæ›¸ãè¾¼ã¿ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
            exit 1
          fi
```

### 7.2 å®šæœŸãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

```python
# scripts/generate_weekly_db_report.py
import asyncio
from datetime import datetime, timedelta
from jinja2 import Template

async def generate_weekly_report():
    """
    é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    """
    # å„ç¨®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
    n_plus_one = await fetch_n_plus_one_issues()
    cache_issues = await fetch_cache_inconsistencies()
    transaction_issues = await fetch_missing_transactions()
    connection_usage = await fetch_connection_pool_usage()
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    last_week = await fetch_last_week_metrics()
    trend = calculate_trend(last_week, {
        'n_plus_one': len(n_plus_one),
        'cache': len(cache_issues),
        'transactions': len(transaction_issues)
    })
    
    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    template = Template('''
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å“è³ªé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ
    
    **æœŸé–“**: {{ start_date }} - {{ end_date }}
    
    ## ã‚µãƒãƒªãƒ¼
    
    | ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ä»Šé€± | å…ˆé€± | å¤‰åŒ– |
    |----------|------|------|------|
    | N+1å•é¡Œ | {{ metrics.n_plus_one }} | {{ last_week.n_plus_one }} | {{ trend.n_plus_one }} |
    | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸æ•´åˆ | {{ metrics.cache }} | {{ last_week.cache }} | {{ trend.cache }} |
    | ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç† | {{ metrics.transactions }} | {{ last_week.transactions }} | {{ trend.transactions }} |
    
    ## é‡è¦åº¦ã®é«˜ã„å•é¡Œ Top 10
    
    {% for issue in top_issues %}
    ### {{ loop.index }}. {{ issue.file }}
    - **ã‚¿ã‚¤ãƒ—**: {{ issue.type }}
    - **å½±éŸ¿ç¯„å›²**: {{ issue.impact_score }}
    - **æ¨å¥¨å¯¾å¿œ**: {{ issue.recommendation }}
    {% endfor %}
    
    ## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¥ã®çµ±è¨ˆ
    
    ### MySQL
    - ã‚¯ã‚¨ãƒªæ•°: {{ db_stats.mysql.query_count }}
    - å¹³å‡è¤‡é›‘åº¦: {{ db_stats.mysql.avg_complexity }}
    
    ### Cassandra
    - CQLå®Ÿè¡Œæ•°: {{ db_stats.cassandra.query_count }}
    - Consistency Levelé•å: {{ db_stats.cassandra.cl_violations }}
    
    ### Elasticsearch
    - æ¤œç´¢ã‚¯ã‚¨ãƒªæ•°: {{ db_stats.elasticsearch.query_count }}
    - è¤‡é›‘ãªã‚¯ã‚¨ãƒª: {{ db_stats.elasticsearch.complex_queries }}
    
    ### Redis
    - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ“ä½œæ•°: {{ db_stats.redis.operation_count }}
    - TTLæœªè¨­å®š: {{ db_stats.redis.no_ttl_count }}
    
    ## æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    
    {% for action in recommended_actions %}
    - [ ] {{ action.description }} (å„ªå…ˆåº¦: {{ action.priority }})
    {% endfor %}
    ''')
    
    report = template.render(
        start_date=(datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d'),
        end_date=datetime.now().strftime('%Y-%m-%d'),
        metrics={
            'n_plus_one': len(n_plus_one),
            'cache': len(cache_issues),
            'transactions': len(transaction_issues)
        },
        last_week=last_week,
        trend=trend,
        top_issues=get_top_issues(n_plus_one, cache_issues, transaction_issues),
        db_stats=await fetch_db_statistics(),
        recommended_actions=generate_recommended_actions()
    )
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ãƒ»é€ä¿¡
    save_report(report)
    send_to_slack(report)
    send_email(report)

if __name__ == '__main__':
    asyncio.run(generate_weekly_report())
```

---

## 8. å®Ÿè£…å„ªå…ˆåº¦ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### ãƒ•ã‚§ãƒ¼ã‚º1: åŸºæœ¬çš„ãªDBè§£æ (Week 1-3)
**ç›®æ¨™**: SQLã‚¯ã‚¨ãƒªã®åŸºæœ¬çš„ãªæ¤œå‡ºã¨é–¢ä¿‚æ§‹ç¯‰

- [ ] SQL/CQLãƒ‘ãƒ¼ã‚µãƒ¼ã®å®Ÿè£…
- [ ] DatabaseQueryãƒãƒ¼ãƒ‰ã®ä½œæˆ
- [ ] EXECUTES_QUERYé–¢ä¿‚ã®æ§‹ç¯‰
- [ ] åŸºæœ¬çš„ãªN+1å•é¡Œã®æ¤œå‡º

**æˆæœç‰©**:
- SQLè§£æã‚¨ãƒ³ã‚¸ãƒ³
- Neo4jã¸ã®DBé–¢ä¿‚ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
- N+1å•é¡Œæ¤œå‡ºAPI

### ãƒ•ã‚§ãƒ¼ã‚º2: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³è§£æ (Week 4-5)
**ç›®æ¨™**: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã®æ¤œå‡º

- [ ] @Transactionalã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è§£æ
- [ ] ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º
- [ ] TransactionBoundaryãƒãƒ¼ãƒ‰ã®ä½œæˆ
- [ ] ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç†ã®æ¤œå‡º

**æˆæœç‰©**:
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡ºAPI

### ãƒ•ã‚§ãƒ¼ã‚º3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥è§£æ (Week 6-7)
**ç›®æ¨™**: Redisã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¿½è·¡

- [ ] Redisæ“ä½œã®æ¤œå‡º
- [ ] CacheOperationãƒãƒ¼ãƒ‰ã®ä½œæˆ
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–è¿½è·¡
- [ ] ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸æ•´åˆæ¤œå‡º

**æˆæœç‰©**:
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥è§£æã‚¨ãƒ³ã‚¸ãƒ³
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯API

### ãƒ•ã‚§ãƒ¼ã‚º4: è¤‡æ•°DBå¯¾å¿œ (Week 8-10)
**ç›®æ¨™**: Cassandraã€Elasticsearchç‰¹åŒ–æ©Ÿèƒ½

- [ ] Cassandra CQLè§£æ
- [ ] Elasticsearch DSLè§£æ
- [ ] æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«æ¤œè¨¼
- [ ] ã‚¯ãƒ­ã‚¹DBæ“ä½œã®æ¤œå‡º

**æˆæœç‰©**:
- ãƒãƒ«ãƒDBè§£æå¯¾å¿œ
- DBç‰¹åŒ–å‹å•é¡Œæ¤œå‡º

### ãƒ•ã‚§ãƒ¼ã‚º5: UIé–‹ç™º (Week 11-13)
**ç›®æ¨™**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å°‚ç”¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- [ ] ã‚¯ã‚¨ãƒªå½±éŸ¿ç¯„å›²ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼
- [ ] N+1å•é¡Œãƒªã‚¹ãƒˆè¡¨ç¤º
- [ ] ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½

**æˆæœç‰©**:
- Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•è¡¨ç¤º

### ãƒ•ã‚§ãƒ¼ã‚º6: CI/CDçµ±åˆ (Week 14-15)
**ç›®æ¨™**: è‡ªå‹•åŒ–ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆ

- [ ] GitHub Actionsçµ±åˆ
- [ ] PRè‡ªå‹•ã‚³ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½
- [ ] é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ
- [ ] Slacké€šçŸ¥

**æˆæœç‰©**:
- CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

---

## 9. æˆåŠŸæŒ‡æ¨™ (ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç‰¹åŒ–)

### 9.1 æ¤œå‡ºç²¾åº¦

| å•é¡Œã‚¿ã‚¤ãƒ— | ç›®æ¨™æ¤œå‡ºç‡ | èª¤æ¤œå‡ºç‡ç›®æ¨™ |
|----------|-----------|------------|
| N+1å•é¡Œ | > 90% | < 10% |
| ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æœªç®¡ç† | > 95% | < 5% |
| ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¸æ•´åˆ | > 85% | < 15% |
| ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸è¶³ | > 80% | < 20% |

### 9.2 ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ

| æŒ‡æ¨™ | ç›®æ¨™ | æ¸¬å®šæ–¹æ³• |
|-----|------|---------|
| ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚°æ¤œå‡ºæ™‚é–“ | 90%çŸ­ç¸® | 1æ™‚é–“ â†’ 6åˆ† |
| æœ¬ç•ªéšœå®³ã®äº‹å‰æ¤œå‡º | 80%ä»¥ä¸Š | ãƒªãƒªãƒ¼ã‚¹å‰ã®æ¤œå‡ºç‡ |
| ã‚¯ã‚¨ãƒªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ | å¹³å‡50%å‘ä¸Š | ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ æ¸¬å®š |
| ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆã®å‰Šæ¸› | 70%å‰Šæ¸› | ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•° |

---

## 10. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å³åº§ã«ç¢ºèªãŒå¿…è¦ãªäº‹é …

1. **æ—¢å­˜ã®ORMãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**
   - ä½¿ç”¨ã—ã¦ã„ã‚‹ORM/ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ä½•ã§ã—ã‚‡ã†ã‹?
     - Hibernate / JPA (Java)
     - MyBatis (Java)
     - Entity Framework (C#)
     - GORM (Go)
     - TypeORM (TypeScript)

2. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç®¡ç†**
   - ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ¼ãƒ«ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ã¯?
   - å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¥ç¶šæ•°åˆ¶é™ã¯?

3. **æ—¢çŸ¥ã®å•é¡Œ**
   - ç¾åœ¨æœ€ã‚‚é »ç¹ã«ç™ºç”Ÿã—ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã®ãƒã‚°ã¯ä½•ã§ã—ã‚‡ã†ã‹?
   - ç›´è¿‘ã§å¤§ããªå½±éŸ¿ã‚’ä¸ãˆãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯?

4. **å„ªå…ˆåº¦**
   - 5ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¸­ã§ã€æœ€ã‚‚å•é¡ŒãŒå¤šã„ã®ã¯ã©ã‚Œã§ã—ã‚‡ã†ã‹?
   - æœ€åˆã«åˆ†æã™ã¹ããƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å„ªå…ˆé †ä½ã¯?

### ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—é–‹ç™ºã®ææ¡ˆ

ã¾ãšã¯1ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹(ä¾‹: MySQL)ã«çµã£ãŸå°è¦æ¨¡ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’2é€±é–“ã§é–‹ç™ºã—ã€åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨ã‚’ã”ææ¡ˆã—ã¾ã™ã€‚

**ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚¹ã‚³ãƒ¼ãƒ—**:
- MySQLé–¢é€£ã®N+1å•é¡Œæ¤œå‡º
- ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œãƒã‚§ãƒƒã‚¯
- ç°¡æ˜“ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- 100-200ãƒ•ã‚¡ã‚¤ãƒ«è¦æ¨¡ã§ã®å‹•ä½œç¢ºèª

---

**æœ¬ä»•æ§˜æ›¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.1 (Database Extension)  
**æœ€çµ‚æ›´æ–°æ—¥**: 2025å¹´10æœˆ26æ—¥
