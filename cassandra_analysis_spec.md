# Cassandraç‰¹åŒ–å‹ãƒã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ  è©³ç´°ä»•æ§˜æ›¸

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### 1.1 Cassandraç‰¹æœ‰ã®èª²é¡Œ

Cassandraã¯åˆ†æ•£NoSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã‚ã‚Šã€RDBMS ã¨ã¯æ ¹æœ¬çš„ã«ç•°ãªã‚‹è¨­è¨ˆæ€æƒ³ã‚’æŒã¡ã¾ã™ã€‚ãã®ãŸã‚ã€ä»¥ä¸‹ã®ã‚ˆã†ãªç‰¹æœ‰ã®å•é¡ŒãŒç™ºç”Ÿã—ã‚„ã™ããªã‚Šã¾ã™:

| å•é¡Œã‚«ãƒ†ã‚´ãƒª | ç™ºç”Ÿé »åº¦ | å½±éŸ¿åº¦ | æ¤œå‡ºé›£æ˜“åº¦ | ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ |
|------------|---------|--------|-----------|------------------|
| æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«(CL)ã®èª¤è¨­å®š | é«˜ | ğŸ”´ è‡´å‘½çš„ | é«˜ | ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆã€èª­ã¿å–ã‚Šå¤±æ•— |
| Partition Keyè¨­è¨ˆãƒŸã‚¹ | ä¸­ | ğŸ”´ è‡´å‘½çš„ | é«˜ | ãƒ›ãƒƒãƒˆã‚¹ãƒãƒƒãƒˆã€æ€§èƒ½åŠ£åŒ– |
| ALLOW FILTERINGã®ä½¿ç”¨ | é«˜ | ğŸŸ¡ æ·±åˆ» | ä½ | ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ |
| Secondary Indexã®èª¤ç”¨ | ä¸­ | ğŸŸ¡ æ·±åˆ» | ä¸­ | ã‚¹ã‚­ãƒ£ãƒ³ç¯„å›²æ‹¡å¤§ |
| å¤§é‡ãƒãƒƒãƒå‡¦ç† | ä¸­ | ğŸŸ¡ æ·±åˆ» | ä¸­ | ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼è² è· |
| Tombstoneè“„ç© | ä½ | ğŸŸ¡ æ·±åˆ» | é«˜ | èª­ã¿å–ã‚Šæ€§èƒ½ä½ä¸‹ |
| ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šä¸è¶³ | é«˜ | ğŸŸ  ä¸­ç¨‹åº¦ | ä¸­ | ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ³ã‚° |
| Prepared Statementã®æœªä½¿ç”¨ | é«˜ | ğŸŸ  ä¸­ç¨‹åº¦ | ä½ | ãƒ‘ãƒ¼ã‚¹è² è·å¢—å¤§ |

### 1.2 æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®ç›®çš„

Cassandraç‰¹æœ‰ã®å•é¡Œã‚’**ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«**ã§äº‹å‰ã«æ¤œå‡ºã—ã€æœ¬ç•ªéšœå®³ã‚’æœªç„¶ã«é˜²ãã“ã¨ã‚’ç›®çš„ã¨ã—ã¾ã™ã€‚

**ä¸»è¦æ©Ÿèƒ½**:
1. **CQLé™çš„è§£æ**: ã‚³ãƒ¼ãƒ‰å†…ã®CQLã‚’æŠ½å‡ºã—ã€å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
2. **æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«è¿½è·¡**: èª­ã¿æ›¸ãã®CLã‚’è¿½è·¡ã—ã€ä¸æ•´åˆãƒªã‚¹ã‚¯ã‚’è©•ä¾¡
3. **ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼**: Partition Keyä½¿ç”¨ã®æ¤œè¨¼
4. **å½±éŸ¿ç¯„å›²åˆ†æ**: ãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›´æ™‚ã®å½±éŸ¿ã‚’å³åº§ã«ç‰¹å®š
5. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒªã‚¹ã‚¯è©•ä¾¡**: ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’äºˆæ¸¬

---

## 2. Cassandraç‰¹åŒ–å‹ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«

### 2.1 æ‹¡å¼µãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—

#### 2.1.1 CassandraQueryãƒãƒ¼ãƒ‰
```cypher
(:CassandraQuery {
  id: "cql_uuid",
  cqlText: "SELECT * FROM users WHERE user_id = ? AND timestamp > ?",
  queryType: "SELECT|INSERT|UPDATE|DELETE|BATCH",
  
  // æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«
  consistencyLevel: "ONE|QUORUM|ALL|LOCAL_QUORUM|EACH_QUORUM",
  serialConsistency: "SERIAL|LOCAL_SERIAL",
  
  // ã‚¯ã‚¨ãƒªç‰¹æ€§
  usesPartitionKey: true,
  usesClusteringKey: true,
  hasAllowFiltering: false,
  usesSecondaryIndex: false,
  isPrepared: true,
  
  // ãƒãƒƒãƒé–¢é€£
  isBatch: false,
  batchType: "LOGGED|UNLOGGED|COUNTER",
  batchSize: 0,  // ãƒãƒƒãƒå†…ã®æ“ä½œæ•°
  
  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
  estimatedPartitions: 1,  // ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æ•°
  estimatedRows: 100,
  scanType: "single_partition|multi_partition|full_table",
  
  // TTLãƒ»Tombstoneé–¢é€£
  usesTTL: false,
  usesDelete: false,  // DELETEæ“ä½œï¼ˆTombstoneç”Ÿæˆï¼‰
  
  lineNumber: 145,
  methodId: "com.example.CassandraDAO.findUser"
})
```

#### 2.1.2 CassandraTableãƒãƒ¼ãƒ‰
```cypher
(:CassandraTable {
  id: "table_uuid",
  keyspace: "user_data",
  tableName: "users",
  
  // ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©
  partitionKeys: ["user_id"],
  clusteringKeys: ["timestamp"],
  clusteringOrder: "DESC",
  regularColumns: ["email", "name", "status"],
  
  // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
  secondaryIndexes: ["email_idx"],
  materializedViews: ["users_by_email"],
  
  // çµ±è¨ˆæƒ…å ±
  estimatedRowCount: 10000000,
  estimatedPartitionCount: 1000000,
  avgPartitionSize: 10,  // KB
  
  // è¨­å®š
  compactionStrategy: "SizeTieredCompactionStrategy|LeveledCompactionStrategy",
  gcGraceSeconds: 864000,
  
  // ä½¿ç”¨é »åº¦
  readFrequency: "high|medium|low",
  writeFrequency: "high|medium|low",
  
  // å•é¡Œã®æœ‰ç„¡
  hasTombstoneWarning: false,
  hasHotPartitionWarning: false
})
```

#### 2.1.3 CassandraSessionãƒãƒ¼ãƒ‰
```cypher
(:CassandraSession {
  id: "session_uuid",
  clusterName: "production_cluster",
  contactPoints: ["10.0.1.1", "10.0.1.2", "10.0.1.3"],
  localDatacenter: "dc1",
  
  // æ¥ç¶šè¨­å®š
  defaultConsistencyLevel: "LOCAL_QUORUM",
  defaultTimeout: 12000,  // ms
  maxConnections: 8,
  
  // ä½¿ç”¨ç®‡æ‰€
  usedByClasses: ["UserDAO", "OrderDAO"],
  configLocation: "/config/cassandra.yml"
})
```

#### 2.1.4 CassandraDataModelãƒãƒ¼ãƒ‰
```cypher
(:CassandraDataModel {
  id: "model_uuid",
  entityName: "User",
  mappingType: "manual|datastax_mapper|spring_data",
  
  // ãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
  tableName: "users",
  keyspace: "user_data",
  
  // ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
  partitionKeyField: "userId",
  clusteringKeyFields: ["timestamp"],
  
  // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã§ã®ä½¿ç”¨
  usedInClasses: ["UserService", "UserRepository"]
})
```

### 2.2 Cassandraç‰¹åŒ–å‹é–¢ä¿‚æ€§

#### 2.2.1 EXECUTES_CQL
```cypher
(:Method)-[:EXECUTES_CQL {
  frequency: 5,
  isConditional: false,
  isInLoop: false,  // ãƒ«ãƒ¼ãƒ—å†…ã§ã®å®Ÿè¡Œï¼ˆå±é™ºï¼‰
  isAsync: true,
  lineNumber: 145,
  
  // æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®å‹•çš„è¨­å®š
  clIsDynamic: false,  // å®Ÿè¡Œæ™‚ã«å¤‰æ›´ã•ã‚Œã‚‹ã‹
  clVariableName: "consistencyLevel"
}]->(:CassandraQuery)
```

#### 2.2.2 ACCESSES_CASSANDRA_TABLE
```cypher
(:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE {
  operation: "read|write|readwrite",
  usesPartitionKey: true,
  partitionKeyCount: 1,  // ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³æ•°
  isFullScan: false,
  estimatedCost: 1.5
}]->(:CassandraTable)
```

#### 2.2.3 CONSISTENCY_MISMATCH
```cypher
(:CassandraQuery)-[:CONSISTENCY_MISMATCH {
  readCL: "ONE",
  writeCL: "QUORUM",
  riskLevel: "high|medium|low",
  dataLossRisk: true
}]->(:CassandraQuery)
```

#### 2.2.4 USES_CASSANDRA_SESSION
```cypher
(:Method)-[:USES_CASSANDRA_SESSION {
  isDirect: true,  // ç›´æ¥ä½¿ç”¨ vs DAOãƒ¬ã‚¤ãƒ¤ãƒ¼çµŒç”±
  sessionVariable: "session"
}]->(:CassandraSession)
```

#### 2.2.5 HOT_PARTITION_RISK
```cypher
(:CassandraQuery)-[:HOT_PARTITION_RISK {
  accessPattern: "sequential|random|time_series",
  riskScore: 8.5,
  recommendation: "Add bucketing to partition key"
}]->(:CassandraTable)
```

---

## 3. Cassandra CQLè§£æã‚¨ãƒ³ã‚¸ãƒ³

### 3.1 CQLãƒ‘ãƒ¼ã‚µãƒ¼ã®å®Ÿè£…

#### 3.1.1 Java (DataStax Driver) è§£æ
```python
import javalang
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class CassandraDriverCall:
    """DataStax Driver ã®å‘¼ã³å‡ºã—æƒ…å ±"""
    method_name: str
    cql_text: str
    consistency_level: Optional[str]
    is_prepared: bool
    is_async: bool
    line_number: int

class CassandraJavaAnalyzer:
    """
    Javaã‚³ãƒ¼ãƒ‰ã‹ã‚‰Cassandraæ“ä½œã‚’æŠ½å‡º
    """
    
    def __init__(self):
        self.driver_classes = [
            'Session',
            'CqlSession', 
            'Cluster',
            'PreparedStatement',
            'BoundStatement',
            'ResultSet'
        ]
        
    def analyze_java_file(self, file_path: str) -> List[CassandraDriverCall]:
        """
        Javaãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦Cassandraæ“ä½œã‚’æŠ½å‡º
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        tree = javalang.parse.parse(content)
        calls = []
        
        # Session.execute() ã®æ¤œå‡º
        for path, node in tree.filter(javalang.tree.MethodInvocation):
            if self._is_cassandra_call(node):
                call_info = self._extract_call_info(node, content)
                calls.append(call_info)
        
        return calls
    
    def _is_cassandra_call(self, node: javalang.tree.MethodInvocation) -> bool:
        """
        Cassandraé–¢é€£ã®å‘¼ã³å‡ºã—ã‹åˆ¤å®š
        """
        if node.member in ['execute', 'executeAsync', 'prepare']:
            # session.execute() ã®ã‚ˆã†ãªå‘¼ã³å‡ºã—
            return True
        return False
    
    def _extract_call_info(self, node, content: str) -> CassandraDriverCall:
        """
        å‘¼ã³å‡ºã—æƒ…å ±ã‚’è©³ç´°ã«æŠ½å‡º
        """
        # CQLæ–‡å­—åˆ—ã®æŠ½å‡º
        cql_text = self._extract_cql_from_arguments(node)
        
        # Consistency Levelã®æŠ½å‡º
        consistency_level = self._extract_consistency_level(node, content)
        
        # Prepared Statementåˆ¤å®š
        is_prepared = self._is_prepared_statement(node, content)
        
        # éåŒæœŸå®Ÿè¡Œåˆ¤å®š
        is_async = node.member == 'executeAsync'
        
        return CassandraDriverCall(
            method_name=node.member,
            cql_text=cql_text,
            consistency_level=consistency_level,
            is_prepared=is_prepared,
            is_async=is_async,
            line_number=node.position.line if hasattr(node, 'position') else 0
        )
    
    def _extract_cql_from_arguments(self, node) -> str:
        """
        ãƒ¡ã‚½ãƒƒãƒ‰å¼•æ•°ã‹ã‚‰CQLæ–‡å­—åˆ—ã‚’æŠ½å‡º
        """
        if node.arguments:
            for arg in node.arguments:
                if isinstance(arg, javalang.tree.Literal):
                    # æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«
                    return arg.value.strip('"\'')
                elif isinstance(arg, javalang.tree.MemberReference):
                    # å®šæ•°å‚ç…§ã®å ´åˆã¯å®šæ•°å®šç¾©ã‚’æ¢ã™
                    return self._resolve_constant(arg.member)
        return ""
    
    def _extract_consistency_level(self, node, content: str) -> Optional[str]:
        """
        Consistency Levelã®è¨­å®šã‚’æŠ½å‡º
        
        ãƒ‘ã‚¿ãƒ¼ãƒ³:
        1. statement.setConsistencyLevel(ConsistencyLevel.QUORUM)
        2. executeStatement(stmt, ConsistencyLevel.ONE)
        3. session.execute(SimpleStatement.builder(cql).setConsistencyLevel(...))
        """
        # SimpleStatementãƒ“ãƒ«ãƒ€ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
        if 'SimpleStatement.builder' in content:
            cl_match = re.search(
                r'setConsistencyLevel\(ConsistencyLevel\.(\w+)\)',
                content
            )
            if cl_match:
                return cl_match.group(1)
        
        # ç›´æ¥è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³
        cl_match = re.search(
            r'ConsistencyLevel\.(\w+)',
            content[max(0, node.position.line - 5):node.position.line + 5]
        )
        if cl_match:
            return cl_match.group(1)
        
        return None
    
    def _is_prepared_statement(self, node, content: str) -> bool:
        """
        Prepared Statementã®ä½¿ç”¨ã‚’åˆ¤å®š
        """
        # session.prepare() ã®æ¤œå‡º
        if 'prepare' in content:
            return True
        
        # PreparedStatementå‹ã®å¤‰æ•°ä½¿ç”¨
        if 'PreparedStatement' in content:
            return True
        
        return False

class CassandraQueryAnalyzer:
    """
    CQLæ–‡ã‚’è©³ç´°ã«è§£æ
    """
    
    def analyze_cql(self, cql: str) -> dict:
        """
        CQLæ–‡ã‚’è§£æã—ã¦å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        """
        cql_upper = cql.upper()
        
        result = {
            'query_type': self._get_query_type(cql_upper),
            'uses_partition_key': self._uses_partition_key(cql),
            'has_allow_filtering': 'ALLOW FILTERING' in cql_upper,
            'uses_secondary_index': self._uses_secondary_index(cql),
            'is_batch': 'BEGIN BATCH' in cql_upper,
            'scan_type': self._determine_scan_type(cql),
            'issues': []
        }
        
        # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
        if result['has_allow_filtering']:
            result['issues'].append({
                'severity': 'high',
                'type': 'ALLOW_FILTERING_DETECTED',
                'message': 'ALLOW FILTERINGä½¿ç”¨: å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ã®å¯èƒ½æ€§',
                'recommendation': 'Materialized Viewã¾ãŸã¯ã‚»ã‚«ãƒ³ãƒ€ãƒªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½¿ç”¨ã‚’æ¤œè¨'
            })
        
        if not result['uses_partition_key'] and result['query_type'] == 'SELECT':
            result['issues'].append({
                'severity': 'critical',
                'type': 'NO_PARTITION_KEY',
                'message': 'Partition Keyæœªä½¿ç”¨: å…¨ãƒãƒ¼ãƒ‰ã‚¹ã‚­ãƒ£ãƒ³',
                'recommendation': 'WHEREå¥ã«Partition Keyã‚’å«ã‚ã‚‹'
            })
        
        if result['uses_secondary_index']:
            result['issues'].append({
                'severity': 'medium',
                'type': 'SECONDARY_INDEX_USAGE',
                'message': 'Secondary Indexä½¿ç”¨: ä½åŠ¹ç‡ã®å¯èƒ½æ€§',
                'recommendation': 'ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®è¦‹ç›´ã—ã‚’æ¨å¥¨'
            })
        
        return result
    
    def _get_query_type(self, cql: str) -> str:
        """ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        if cql.startswith('SELECT'):
            return 'SELECT'
        elif cql.startswith('INSERT'):
            return 'INSERT'
        elif cql.startswith('UPDATE'):
            return 'UPDATE'
        elif cql.startswith('DELETE'):
            return 'DELETE'
        elif 'BEGIN BATCH' in cql:
            return 'BATCH'
        return 'UNKNOWN'
    
    def _uses_partition_key(self, cql: str) -> bool:
        """
        WHEREå¥ã§Partition Keyã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹åˆ¤å®š
        
        æ³¨: å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã¨ç…§åˆãŒå¿…è¦
        ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ¨å®š
        """
        # WHEREå¥ã®æŠ½å‡º
        where_match = re.search(r'WHERE\s+(.+?)(?:ALLOW|ORDER|LIMIT|$)', cql, re.IGNORECASE)
        if not where_match:
            return False
        
        where_clause = where_match.group(1)
        
        # ç­‰ä¾¡æ¡ä»¶ã®å­˜åœ¨ï¼ˆPartition Keyã¯é€šå¸¸ç­‰ä¾¡æ¡ä»¶ï¼‰
        has_equality = '=' in where_clause and 'IN' not in where_clause.upper()
        
        return has_equality
    
    def _uses_secondary_index(self, cql: str) -> bool:
        """
        Secondary Indexã‚’ä½¿ç”¨ã™ã‚‹å¯èƒ½æ€§ã‚’æ¨å®š
        """
        # WHEREå¥ã«éç­‰ä¾¡æ¡ä»¶ãŒã‚ã‚‹å ´åˆã€Secondary Indexã®å¯èƒ½æ€§
        where_match = re.search(r'WHERE\s+(.+?)(?:ALLOW|ORDER|LIMIT|$)', cql, re.IGNORECASE)
        if not where_match:
            return False
        
        where_clause = where_match.group(1)
        
        # >, <, >=, <= ãªã©ã®ç¯„å›²æ¡ä»¶
        has_range = any(op in where_clause for op in ['>', '<', '>=', '<='])
        
        return has_range
    
    def _determine_scan_type(self, cql: str) -> str:
        """
        ã‚¹ã‚­ãƒ£ãƒ³ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
        """
        cql_upper = cql.upper()
        
        if 'ALLOW FILTERING' in cql_upper:
            return 'full_table'
        
        where_match = re.search(r'WHERE\s+(.+?)(?:ALLOW|ORDER|LIMIT|$)', cql_upper)
        if not where_match:
            return 'full_table'
        
        where_clause = where_match.group(1)
        
        # Partition Key + Clustering Key ã®ä¸¡æ–¹ã‚’ä½¿ç”¨
        if '=' in where_clause and 'AND' in where_clause:
            return 'single_partition'
        
        # INå¥ã‚’ä½¿ç”¨ï¼ˆè¤‡æ•°ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ï¼‰
        if 'IN' in where_clause:
            return 'multi_partition'
        
        return 'single_partition'

class CassandraBatchAnalyzer:
    """
    BATCHæ“ä½œã®è§£æ
    """
    
    def analyze_batch(self, cql: str) -> dict:
        """
        BATCHå‡¦ç†ã‚’è§£æ
        """
        batch_type = self._get_batch_type(cql)
        statements = self._extract_batch_statements(cql)
        
        result = {
            'batch_type': batch_type,
            'statement_count': len(statements),
            'affects_multiple_partitions': self._affects_multiple_partitions(statements),
            'issues': []
        }
        
        # å¤§é‡ãƒãƒƒãƒã®è­¦å‘Š
        if len(statements) > 100:
            result['issues'].append({
                'severity': 'high',
                'type': 'LARGE_BATCH',
                'message': f'å¤§é‡ãƒãƒƒãƒå‡¦ç†: {len(statements)}ä»¶',
                'recommendation': '100ä»¶ä»¥ä¸‹ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨'
            })
        
        # è¤‡æ•°ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¸ã®LOGGED BATCH
        if batch_type == 'LOGGED' and result['affects_multiple_partitions']:
            result['issues'].append({
                'severity': 'medium',
                'type': 'LOGGED_BATCH_MULTI_PARTITION',
                'message': 'LOGGED BATCHã§è¤‡æ•°ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«æ›¸ãè¾¼ã¿',
                'recommendation': 'UNLOGGED BATCHã®ä½¿ç”¨ã‚’æ¤œè¨ï¼ˆå†ªç­‰æ€§ã‚’ç¢ºä¿ã§ãã‚‹å ´åˆï¼‰'
            })
        
        return result
    
    def _get_batch_type(self, cql: str) -> str:
        """ãƒãƒƒãƒã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        cql_upper = cql.upper()
        if 'BEGIN UNLOGGED BATCH' in cql_upper:
            return 'UNLOGGED'
        elif 'BEGIN COUNTER BATCH' in cql_upper:
            return 'COUNTER'
        else:
            return 'LOGGED'
    
    def _extract_batch_statements(self, cql: str) -> List[str]:
        """BATCHå†…ã®å€‹åˆ¥æ–‡ã‚’æŠ½å‡º"""
        # ç°¡æ˜“å®Ÿè£…: ã‚»ãƒŸã‚³ãƒ­ãƒ³ã§åˆ†å‰²
        statements = cql.split(';')
        # BEGIN BATCH ã¨ APPLY BATCH ã‚’é™¤å¤–
        return [s.strip() for s in statements 
                if s.strip() and 'BEGIN BATCH' not in s and 'APPLY BATCH' not in s]
    
    def _affects_multiple_partitions(self, statements: List[str]) -> bool:
        """è¤‡æ•°ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«å½±éŸ¿ã™ã‚‹ã‹åˆ¤å®š"""
        # ç°¡æ˜“å®Ÿè£…: ç•°ãªã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’æ¤œå‡º
        tables = set()
        for stmt in statements:
            match = re.search(r'(?:FROM|INTO|UPDATE)\s+(\w+)', stmt, re.IGNORECASE)
            if match:
                tables.add(match.group(1))
        return len(tables) > 1
```

#### 3.1.2 TypeScript (cassandra-driver) è§£æ
```python
class CassandraTypeScriptAnalyzer:
    """
    TypeScriptã‚³ãƒ¼ãƒ‰ã‹ã‚‰Cassandraæ“ä½œã‚’æŠ½å‡º
    """
    
    def analyze_typescript_file(self, file_path: str) -> List[dict]:
        """
        TypeScriptãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Cassandraæ“ä½œã‚’æŠ½å‡º
        
        å¯¾è±¡ãƒ‘ã‚¿ãƒ¼ãƒ³:
        - client.execute(query, params, options)
        - client.batch(queries, options)
        - await client.execute()
        """
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        operations = []
        
        # client.execute() ã®æ¤œå‡º
        execute_pattern = r'(?:await\s+)?client\.execute\((.*?)\)'
        for match in re.finditer(execute_pattern, content, re.DOTALL):
            args = match.group(1)
            operation = self._parse_execute_call(args, content)
            operations.append(operation)
        
        # client.batch() ã®æ¤œå‡º
        batch_pattern = r'(?:await\s+)?client\.batch\((.*?)\)'
        for match in re.finditer(batch_pattern, content, re.DOTALL):
            args = match.group(1)
            operation = self._parse_batch_call(args, content)
            operations.append(operation)
        
        return operations
    
    def _parse_execute_call(self, args: str, content: str) -> dict:
        """
        executeå‘¼ã³å‡ºã—ã‚’ãƒ‘ãƒ¼ã‚¹
        """
        # ç¬¬ä¸€å¼•æ•°ãŒCQLæ–‡
        cql_match = re.search(r'[\'"`](.+?)[\'"`]', args)
        cql = cql_match.group(1) if cql_match else ""
        
        # Consistency Level (optionsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…)
        cl_match = re.search(r'consistency:\s*types\.consistencies\.(\w+)', args)
        consistency_level = cl_match.group(1) if cl_match else None
        
        # Prepared Statementåˆ¤å®š
        is_prepared = 'prepare' in content and cql in content
        
        return {
            'type': 'execute',
            'cql': cql,
            'consistency_level': consistency_level,
            'is_prepared': is_prepared,
            'is_async': 'await' in args
        }
```

### 3.2 æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®è¿½è·¡

```python
class ConsistencyLevelTracker:
    """
    Consistency Levelè¨­å®šã‚’è¿½è·¡ã—ã€ä¸æ•´åˆã‚’æ¤œå‡º
    """
    
    def __init__(self, neo4j_driver):
        self.db = neo4j_driver
        self.cl_hierarchy = {
            'ANY': 0,
            'ONE': 1,
            'TWO': 2,
            'THREE': 3,
            'QUORUM': 4,
            'LOCAL_QUORUM': 4,
            'EACH_QUORUM': 5,
            'ALL': 6,
            'LOCAL_ONE': 1,
            'LOCAL_SERIAL': 7,
            'SERIAL': 7
        }
    
    def track_consistency_levels(self, table_name: str, keyspace: str):
        """
        ç‰¹å®šãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã®æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã‚’è¿½è·¡
        """
        query = """
        MATCH (table:CassandraTable {tableName: $tableName, keyspace: $keyspace})
        MATCH (query:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE]->(table)
        MATCH (method:Method)-[:EXECUTES_CQL]->(query)
        RETURN query.queryType as queryType,
               query.consistencyLevel as consistencyLevel,
               method.name as methodName,
               query.cqlText as cql
        """
        
        results = self.db.execute_query(
            query, 
            tableName=table_name, 
            keyspace=keyspace
        )
        
        # èª­ã¿æ›¸ãã®CLã‚’åˆ†é¡
        read_cls = []
        write_cls = []
        
        for r in results:
            if r['queryType'] == 'SELECT':
                read_cls.append({
                    'cl': r['consistencyLevel'],
                    'method': r['methodName']
                })
            else:
                write_cls.append({
                    'cl': r['consistencyLevel'],
                    'method': r['methodName']
                })
        
        # ä¸æ•´åˆã®æ¤œå‡º
        inconsistencies = self._detect_inconsistencies(read_cls, write_cls)
        
        return {
            'table': table_name,
            'read_consistency_levels': read_cls,
            'write_consistency_levels': write_cls,
            'inconsistencies': inconsistencies
        }
    
    def _detect_inconsistencies(self, read_cls: List[dict], write_cls: List[dict]) -> List[dict]:
        """
        èª­ã¿æ›¸ãã®CLã®ä¸æ•´åˆã‚’æ¤œå‡º
        
        ãƒ«ãƒ¼ãƒ«:
        R + W > RF (Replication Factor)
        
        ä¾‹: RF=3ã®å ´åˆ
        - R=QUORUM(2) + W=QUORUM(2) = 4 > 3 âœ“ æ•´åˆæ€§ä¿è¨¼
        - R=ONE(1) + W=ONE(1) = 2 < 3 âœ— ä¸æ•´åˆã®å¯èƒ½æ€§
        """
        issues = []
        
        for read in read_cls:
            for write in write_cls:
                read_level = self.cl_hierarchy.get(read['cl'], 0)
                write_level = self.cl_hierarchy.get(write['cl'], 0)
                
                # RF=3ã‚’ä»®å®šï¼ˆæœ¬æ¥ã¯å®Ÿéš›ã®RFã‚’å–å¾—ï¼‰
                rf = 3
                
                if read_level + write_level <= rf:
                    issues.append({
                        'severity': 'high',
                        'type': 'CONSISTENCY_VIOLATION',
                        'read_method': read['method'],
                        'read_cl': read['cl'],
                        'write_method': write['method'],
                        'write_cl': write['cl'],
                        'message': f"R({read['cl']}) + W({write['cl']}) <= RF({rf}): ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆã®å¯èƒ½æ€§",
                        'recommendation': 'Quorumã¾ãŸã¯ALLã®ä½¿ç”¨ã‚’æ¤œè¨'
                    })
        
        return issues

class PartitionKeyAnalyzer:
    """
    Partition Keyä½¿ç”¨ã®æ¤œè¨¼
    """
    
    def __init__(self, neo4j_driver):
        self.db = neo4j_driver
    
    def analyze_partition_key_usage(self, table_name: str):
        """
        ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¯ã‚¨ãƒªãŒPartition Keyã‚’é©åˆ‡ã«ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹æ¤œè¨¼
        """
        # ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’å–å¾—
        table_query = """
        MATCH (table:CassandraTable {tableName: $tableName})
        RETURN table.partitionKeys as partitionKeys
        """
        
        table_info = self.db.execute_query(table_query, tableName=table_name).single()
        partition_keys = table_info['partitionKeys']
        
        # ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¯ã‚¨ãƒªã‚’å–å¾—
        query = """
        MATCH (table:CassandraTable {tableName: $tableName})
        MATCH (cql:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE]->(table)
        MATCH (method:Method)-[:EXECUTES_CQL]->(cql)
        RETURN cql.cqlText as cql,
               cql.usesPartitionKey as usesPartitionKey,
               cql.scanType as scanType,
               method.name as methodName
        """
        
        results = self.db.execute_query(query, tableName=table_name)
        
        issues = []
        for r in results:
            if not r['usesPartitionKey']:
                issues.append({
                    'severity': 'critical',
                    'method': r['methodName'],
                    'cql': r['cql'],
                    'type': 'MISSING_PARTITION_KEY',
                    'message': f"Partition Keyæœªä½¿ç”¨: {partition_keys}",
                    'scan_type': r['scanType'],
                    'recommendation': f"WHEREå¥ã«{', '.join(partition_keys)}ã‚’å«ã‚ã‚‹"
                })
        
        return {
            'table': table_name,
            'partition_keys': partition_keys,
            'issues': issues,
            'queries_without_pk': len(issues),
            'total_queries': len(results)
        }
```

---

## 4. Cassandraç‰¹åŒ–å‹åˆ†æã‚¯ã‚¨ãƒª

### 4.1 æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ä¸æ•´åˆã®æ¤œå‡º

```cypher
// åŒä¸€ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®èª­ã¿æ›¸ãã§CLãŒä¸æ•´åˆ
MATCH (table:CassandraTable)
MATCH (readQuery:CassandraQuery {queryType: 'SELECT'})-[:ACCESSES_CASSANDRA_TABLE]->(table)
MATCH (writeQuery:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE]->(table)
WHERE writeQuery.queryType IN ['INSERT', 'UPDATE', 'DELETE']
  AND readQuery.consistencyLevel IS NOT NULL
  AND writeQuery.consistencyLevel IS NOT NULL

WITH table, readQuery, writeQuery,
     CASE readQuery.consistencyLevel
       WHEN 'ONE' THEN 1
       WHEN 'QUORUM' THEN 2
       WHEN 'ALL' THEN 3
       ELSE 0
     END as readLevel,
     CASE writeQuery.consistencyLevel
       WHEN 'ONE' THEN 1
       WHEN 'QUORUM' THEN 2
       WHEN 'ALL' THEN 3
       ELSE 0
     END as writeLevel

// RF=3ã‚’ä»®å®š: R + W <= 3 ã®å ´åˆã¯ä¸æ•´åˆãƒªã‚¹ã‚¯
WHERE readLevel + writeLevel <= 3

MATCH (readMethod:Method)-[:EXECUTES_CQL]->(readQuery)
MATCH (writeMethod:Method)-[:EXECUTES_CQL]->(writeQuery)
MATCH (readMethod)<-[:CONTAINS]-(readClass:Class)<-[:CONTAINS]-(readFile:File)
MATCH (writeMethod)<-[:CONTAINS]-(writeClass:Class)<-[:CONTAINS]-(writeFile:File)

RETURN table.keyspace + '.' + table.tableName as table,
       readFile.path as readLocation,
       readMethod.name as readMethod,
       readQuery.consistencyLevel as readCL,
       writeFile.path as writeLocation,
       writeMethod.name as writeMethod,
       writeQuery.consistencyLevel as writeCL,
       'Data Inconsistency Risk' as issue,
       'Increase Consistency Level to QUORUM or higher' as recommendation
```

### 4.2 ALLOW FILTERINGã®æ¤œå‡º

```cypher
// ALLOW FILTERINGä½¿ç”¨ã®æ¤œå‡º
MATCH (query:CassandraQuery)
WHERE query.hasAllowFiltering = true
MATCH (method:Method)-[:EXECUTES_CQL]->(query)
MATCH (query)-[:ACCESSES_CASSANDRA_TABLE]->(table:CassandraTable)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

RETURN file.path,
       class.name,
       method.name,
       table.tableName,
       query.cqlText,
       query.estimatedRows,
       'ALLOW FILTERING - Full Table Scan Risk' as issue,
       CASE 
         WHEN query.estimatedRows > 100000 THEN 'critical'
         WHEN query.estimatedRows > 10000 THEN 'high'
         ELSE 'medium'
       END as severity,
       'Create Materialized View or redesign data model' as recommendation
ORDER BY query.estimatedRows DESC
```

### 4.3 Partition Keyæœªä½¿ç”¨ã®æ¤œå‡º

```cypher
// Partition Keyã‚’ä½¿ã‚ãªã„SELECTã‚¯ã‚¨ãƒª
MATCH (query:CassandraQuery {queryType: 'SELECT'})
WHERE query.usesPartitionKey = false
  AND query.hasAllowFiltering = false  // ALLOW FILTERINGãªã—ã§PKä¸ä½¿ç”¨
MATCH (method:Method)-[:EXECUTES_CQL]->(query)
MATCH (query)-[:ACCESSES_CASSANDRA_TABLE]->(table:CassandraTable)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

RETURN file.path,
       method.name,
       table.tableName,
       table.partitionKeys,
       query.cqlText,
       query.scanType,
       'Missing Partition Key - Multi-node Scan' as issue,
       'critical' as severity,
       'Add partition key to WHERE clause: ' + table.partitionKeys[0] as recommendation
```

### 4.4 å¤§é‡ãƒãƒƒãƒå‡¦ç†ã®æ¤œå‡º

```cypher
// å¤§é‡ãƒãƒƒãƒå‡¦ç†
MATCH (query:CassandraQuery {isBatch: true})
WHERE query.batchSize > 100
MATCH (method:Method)-[:EXECUTES_CQL]->(query)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

RETURN file.path,
       method.name,
       query.batchType,
       query.batchSize,
       'Large Batch Processing' as issue,
       CASE 
         WHEN query.batchSize > 500 THEN 'critical'
         WHEN query.batchSize > 200 THEN 'high'
         ELSE 'medium'
       END as severity,
       'Split batch into chunks of 100 or less' as recommendation
ORDER BY query.batchSize DESC
```

### 4.5 ãƒ›ãƒƒãƒˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯

```cypher
// æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ›ãƒƒãƒˆãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯
MATCH (query:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE]->(table:CassandraTable)
WHERE table.hasHotPartitionWarning = true
  OR (table.partitionKeys = ['date'] OR table.partitionKeys = ['timestamp'])
MATCH (method:Method)-[:EXECUTES_CQL]->(query)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

WITH table, query, method, file, class,
     query.estimatedPartitions as partitionCount

WHERE partitionCount = 1  // å˜ä¸€ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¸ã®æ›¸ãè¾¼ã¿

RETURN file.path,
       method.name,
       table.tableName,
       table.partitionKeys,
       'Hot Partition Risk - Time-based Partition Key' as issue,
       'high' as severity,
       'Add bucketing: partition_key = (date, bucket)' as recommendation
```

### 4.6 Prepared Statementæœªä½¿ç”¨

```cypher
// Prepared Statementã‚’ä½¿ã£ã¦ã„ãªã„é »ç¹ãªã‚¯ã‚¨ãƒª
MATCH (method:Method)-[exec:EXECUTES_CQL]->(query:CassandraQuery)
WHERE query.isPrepared = false
  AND exec.frequency > 10
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

RETURN file.path,
       method.name,
       query.cqlText,
       exec.frequency,
       'Unprepared Statement - Parse Overhead' as issue,
       CASE 
         WHEN exec.frequency > 100 THEN 'high'
         WHEN exec.frequency > 50 THEN 'medium'
         ELSE 'low'
       END as severity,
       'Use prepared statement to reduce parse overhead' as recommendation
ORDER BY exec.frequency DESC
```

### 4.7 Secondary Indexä½¿ç”¨ã®æ¤œå‡º

```cypher
// Secondary Indexã‚’ä½¿ç”¨ã™ã‚‹ã‚¯ã‚¨ãƒª
MATCH (query:CassandraQuery)
WHERE query.usesSecondaryIndex = true
MATCH (method:Method)-[:EXECUTES_CQL]->(query)
MATCH (query)-[:ACCESSES_CASSANDRA_TABLE]->(table:CassandraTable)
MATCH (method)<-[:CONTAINS]-(class:Class)<-[:CONTAINS]-(file:File)

RETURN file.path,
       method.name,
       table.tableName,
       table.secondaryIndexes,
       query.cqlText,
       'Secondary Index Usage - Performance Concern' as issue,
       'medium' as severity,
       'Consider data model redesign or Materialized View' as recommendation
```

---

## 5. Cassandraç‰¹åŒ–å‹API

```python
from fastapi import FastAPI, Query, HTTPException
from typing import List, Optional

app = FastAPI(title="Cassandra Analysis API")

@app.get("/api/v1/cassandra/health")
async def cassandra_health_check():
    """
    Cassandraé–¢é€£ã‚³ãƒ¼ãƒ‰ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
    """
    # å„ç¨®å•é¡Œã®é›†è¨ˆ
    allow_filtering_count = await count_allow_filtering_issues()
    pk_missing_count = await count_missing_partition_key()
    cl_mismatch_count = await count_consistency_mismatches()
    large_batch_count = await count_large_batches()
    unprepared_count = await count_unprepared_statements()
    
    total_issues = (
        allow_filtering_count + 
        pk_missing_count + 
        cl_mismatch_count + 
        large_batch_count + 
        unprepared_count
    )
    
    health_score = max(0, 100 - (total_issues * 2))
    
    return {
        "health_score": health_score,
        "health_status": "good" if health_score > 80 else "warning" if health_score > 60 else "critical",
        "issues_summary": {
            "allow_filtering": allow_filtering_count,
            "missing_partition_key": pk_missing_count,
            "consistency_mismatch": cl_mismatch_count,
            "large_batch": large_batch_count,
            "unprepared_statement": unprepared_count
        },
        "total_issues": total_issues
    }

@app.get("/api/v1/cassandra/tables/{keyspace}/{table}/analysis")
async def analyze_table(keyspace: str, table: str):
    """
    ç‰¹å®šãƒ†ãƒ¼ãƒ–ãƒ«ã®è©³ç´°åˆ†æ
    """
    # ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    access_patterns = await analyze_table_access_patterns(keyspace, table)
    
    # æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®è¿½è·¡
    cl_tracker = ConsistencyLevelTracker(neo4j_driver)
    cl_analysis = cl_tracker.track_consistency_levels(table, keyspace)
    
    # Partition Keyä½¿ç”¨åˆ†æ
    pk_analyzer = PartitionKeyAnalyzer(neo4j_driver)
    pk_analysis = pk_analyzer.analyze_partition_key_usage(table)
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒªã‚¹ã‚¯è©•ä¾¡
    perf_risks = await assess_performance_risks(keyspace, table)
    
    return {
        "keyspace": keyspace,
        "table": table,
        "access_patterns": access_patterns,
        "consistency_analysis": cl_analysis,
        "partition_key_analysis": pk_analysis,
        "performance_risks": perf_risks,
        "overall_risk_score": calculate_risk_score(cl_analysis, pk_analysis, perf_risks)
    }

@app.get("/api/v1/cassandra/detect/consistency-mismatches")
async def detect_consistency_mismatches():
    """
    æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®ä¸æ•´åˆã‚’æ¤œå‡º
    """
    cypher_query = """
    MATCH (table:CassandraTable)
    MATCH (readQuery:CassandraQuery {queryType: 'SELECT'})-[:ACCESSES_CASSANDRA_TABLE]->(table)
    MATCH (writeQuery:CassandraQuery)-[:ACCESSES_CASSANDRA_TABLE]->(table)
    WHERE writeQuery.queryType IN ['INSERT', 'UPDATE', 'DELETE']
      AND readQuery.consistencyLevel IS NOT NULL
      AND writeQuery.consistencyLevel IS NOT NULL
    
    WITH table, readQuery, writeQuery,
         CASE readQuery.consistencyLevel
           WHEN 'ONE' THEN 1
           WHEN 'QUORUM' THEN 2
           WHEN 'ALL' THEN 3
           ELSE 0
         END as readLevel,
         CASE writeQuery.consistencyLevel
           WHEN 'ONE' THEN 1
           WHEN 'QUORUM' THEN 2
           WHEN 'ALL' THEN 3
           ELSE 0
         END as writeLevel
    
    WHERE readLevel + writeLevel <= 3
    
    MATCH (readMethod:Method)-[:EXECUTES_CQL]->(readQuery)
    MATCH (writeMethod:Method)-[:EXECUTES_CQL]->(writeQuery)
    
    RETURN table.tableName as table,
           readMethod.name as readMethod,
           readQuery.consistencyLevel as readCL,
           writeMethod.name as writeMethod,
           writeQuery.consistencyLevel as writeCL
    """
    
    results = neo4j_driver.execute_query(cypher_query)
    
    return {
        "consistency_mismatches": results,
        "total_count": len(results),
        "severity": "critical" if len(results) > 0 else "low",
        "recommendations": [
            "ä¸¡æ–¹ã®Consistency Levelã‚’QUORUMã«è¨­å®š",
            "Read: QUORUM, Write: ALLã®çµ„ã¿åˆã‚ã›ã‚’æ¤œè¨",
            "ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§è¦ä»¶ã‚’å†ç¢ºèª"
        ]
    }

@app.post("/api/v1/cassandra/simulate/table-change")
async def simulate_table_change(
    keyspace: str,
    table: str,
    change_type: str = Query(..., regex="^(add_column|remove_column|change_partition_key|add_index)$")
):
    """
    Cassandraãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›´ã®å½±éŸ¿ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    # ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‚¯ã‚¨ãƒªã‚’å–å¾—
    affected_queries = await get_affected_queries(keyspace, table)
    
    # å¤‰æ›´ã‚¿ã‚¤ãƒ—ã”ã¨ã®å½±éŸ¿è©•ä¾¡
    impact_assessment = assess_change_impact(change_type, affected_queries)
    
    # ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ã®æ¨å®š
    estimated_downtime = estimate_downtime(change_type, affected_queries)
    
    # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥
    rollback_strategy = generate_rollback_strategy(change_type)
    
    return {
        "keyspace": keyspace,
        "table": table,
        "change_type": change_type,
        "affected_queries": len(affected_queries),
        "affected_methods": [q['method'] for q in affected_queries],
        "impact_level": impact_assessment['level'],
        "impact_details": impact_assessment['details'],
        "estimated_downtime_minutes": estimated_downtime,
        "rollback_strategy": rollback_strategy,
        "migration_steps": generate_migration_steps(change_type, keyspace, table)
    }

def assess_change_impact(change_type: str, affected_queries: List[dict]) -> dict:
    """
    å¤‰æ›´ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå½±éŸ¿è©•ä¾¡
    """
    if change_type == "change_partition_key":
        return {
            "level": "critical",
            "details": [
                "å…¨ã¦ã®ã‚¯ã‚¨ãƒªãŒWHEREå¥ã®å¤‰æ›´å¿…è¦",
                "ãƒ‡ãƒ¼ã‚¿å†é…ç½®ã«ã‚ˆã‚‹å¤§è¦æ¨¡ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
                "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å´ã®å¤§å¹…ãªä¿®æ­£"
            ]
        }
    elif change_type == "remove_column":
        affected_count = sum(1 for q in affected_queries if 'column_name' in q['cql'])
        return {
            "level": "high" if affected_count > 0 else "medium",
            "details": [
                f"{affected_count}å€‹ã®ã‚¯ã‚¨ãƒªãŒå½±éŸ¿ã‚’å—ã‘ã‚‹",
                "SELECT *ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ç®‡æ‰€ã¯å½±éŸ¿ã‚’å—ã‘ãªã„å¯èƒ½æ€§",
                "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã®ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°å¿…è¦"
            ]
        }
    else:
        return {
            "level": "low",
            "details": ["å½±éŸ¿ã¯è»½å¾®"]
        }

def generate_migration_steps(change_type: str, keyspace: str, table: str) -> List[dict]:
    """
    ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †ã‚’ç”Ÿæˆ
    """
    if change_type == "change_partition_key":
        return [
            {
                "step": 1,
                "action": "æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ",
                "command": f"CREATE TABLE {keyspace}.{table}_new (...)",
                "rollback": f"DROP TABLE {keyspace}.{table}_new"
            },
            {
                "step": 2,
                "action": "ãƒ‡ãƒ¼ã‚¿ã‚’æ–°ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚³ãƒ”ãƒ¼",
                "command": "spark-submit copy_data.py",
                "estimated_time": "æ•°æ™‚é–“ã€œæ•°æ—¥"
            },
            {
                "step": 3,
                "action": "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°",
                "command": "Deploy new application version",
                "rollback": "Rollback to previous version"
            },
            {
                "step": 4,
                "action": "æ—§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å‰Šé™¤",
                "command": f"DROP TABLE {keyspace}.{table}",
                "note": "ååˆ†ãªæ¤œè¨¼å¾Œã«å®Ÿè¡Œ"
            }
        ]
    else:
        return [
            {
                "step": 1,
                "action": f"ãƒ†ãƒ¼ãƒ–ãƒ«å¤‰æ›´ã‚’å®Ÿè¡Œ",
                "command": f"ALTER TABLE {keyspace}.{table} ..."
            }
        ]

@app.get("/api/v1/cassandra/recommendations")
async def get_recommendations():
    """
    Cassandraä½¿ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹æ¨å¥¨äº‹é …
    """
    # å®Ÿéš›ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ
    issues = await get_all_issues()
    
    recommendations = []
    
    # ALLOW FILTERINGãŒå¤šã„å ´åˆ
    if issues['allow_filtering_count'] > 10:
        recommendations.append({
            "priority": "high",
            "category": "data_modeling",
            "title": "ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®å†è¨­è¨ˆ",
            "description": "ALLOW FILTERINGã®ä½¿ç”¨ãŒå¤šãæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã«åˆã‚ã›ãŸãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆã‚’æ¨å¥¨ã—ã¾ã™ã€‚",
            "actions": [
                "é »ç¹ãªã‚¯ã‚¨ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®š",
                "Materialized Viewã®ä½œæˆã‚’æ¤œè¨",
                "Query-drivenãªãƒ†ãƒ¼ãƒ–ãƒ«è¨­è¨ˆã¸ã®ç§»è¡Œ"
            ]
        })
    
    # æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ä¸æ•´åˆ
    if issues['cl_mismatch_count'] > 0:
        recommendations.append({
            "priority": "critical",
            "category": "consistency",
            "title": "æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«ã®çµ±ä¸€",
            "description": "èª­ã¿æ›¸ãã®Consistency LevelãŒä¸æ•´åˆã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ä¸æ•´åˆã®ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚",
            "actions": [
                "èª­ã¿æ›¸ãå…±ã«QUORUMã‚’è¨­å®š",
                "CAPå®šç†ã‚’ç†è§£ã—ã€è¦ä»¶ã«åˆã‚ã›ãŸè¨­å®š",
                "æ•´åˆæ€§ãƒ†ã‚¹ãƒˆã®å®Ÿæ–½"
            ]
        })
    
    return {
        "recommendations": recommendations,
        "total_recommendations": len(recommendations)
    }
```

---

## 6. å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ— (Cassandraç‰¹åŒ–)

### Week 1: åŸºæœ¬CQLè§£æ
**ç›®æ¨™**: Javaã‚³ãƒ¼ãƒ‰ã‹ã‚‰CQLã‚’æŠ½å‡º

- [ ] DataStax Driverå‘¼ã³å‡ºã—ã®æ¤œå‡º
- [ ] CQLæ–‡å­—åˆ—ã®æŠ½å‡º
- [ ] åŸºæœ¬çš„ãªCQLãƒ‘ãƒ¼ã‚¹
- [ ] Neo4jã¸ã®CassandraQueryãƒãƒ¼ãƒ‰ä½œæˆ

**æˆæœç‰©**: 
- `CassandraJavaAnalyzer`ã‚¯ãƒ©ã‚¹
- 100ä»¶ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹

### Week 2: æ•´åˆæ€§ãƒ¬ãƒ™ãƒ«è¿½è·¡
**ç›®æ¨™**: CLè¨­å®šã®è¿½è·¡

- [ ] Consistency Levelè¨­å®šã®æ¤œå‡º
- [ ] èª­ã¿æ›¸ãã®CLãƒãƒƒãƒ”ãƒ³ã‚°
- [ ] ä¸æ•´åˆæ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
- [ ] ConsistencyLevelTrackerã®å®Ÿè£…

**æˆæœç‰©**:
- CLè¿½è·¡æ©Ÿèƒ½
- ä¸æ•´åˆæ¤œå‡ºAPI

### Week 3: å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
**ç›®æ¨™**: Cassandraç‰¹æœ‰ã®å•é¡Œã‚’æ¤œå‡º

- [ ] ALLOW FILTERINGæ¤œå‡º
- [ ] Partition Keyæœªä½¿ç”¨æ¤œå‡º
- [ ] å¤§é‡ãƒãƒƒãƒæ¤œå‡º
- [ ] Secondary Indexä½¿ç”¨æ¤œå‡º

**æˆæœç‰©**:
- å•é¡Œæ¤œå‡ºCypherã‚¯ã‚¨ãƒªé›†
- æ¤œå‡ºAPI

### Week 4: çµ±åˆã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
**ç›®æ¨™**: UIã¨ãƒ¬ãƒãƒ¼ãƒˆ

- [ ] Cassandraãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- [ ] å•é¡Œãƒªã‚¹ãƒˆè¡¨ç¤º
- [ ] ãƒ†ãƒ¼ãƒ–ãƒ«åˆ†æãƒ“ãƒ¥ãƒ¼
- [ ] é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

**æˆæœç‰©**:
- Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆ

---

## 7. æˆåŠŸæŒ‡æ¨™ (Cassandraç‰¹åŒ–)

| æŒ‡æ¨™ | ç¾çŠ¶ | ç›®æ¨™ | æ¸¬å®šæ–¹æ³• |
|-----|------|------|---------|
| ALLOW FILTERINGæ¤œå‡º | - | 95%ä»¥ä¸Š | æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã®æ¯”è¼ƒ |
| CLä¸æ•´åˆæ¤œå‡º | - | 100% | å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º |
| Cassandraèµ·å› ã®éšœå®³ | ? | 80%å‰Šæ¸› | ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•° |
| ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªå‰Šæ¸› | - | 50%å‰Šæ¸› | P95ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ  |

---

## 8. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### å³åº§ã«å¿…è¦ãªæƒ…å ±

1. **ä½¿ç”¨ã—ã¦ã„ã‚‹Cassandraãƒ‰ãƒ©ã‚¤ãƒãƒ¼**
   - DataStax Java Driver (ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
   - cassandra-driver (Node.js)
   - gocql (Go)
   - ãã®ä»–

2. **ç¾åœ¨ã®Cassandraæ§‹æˆ**
   - ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚º
   - Replication Factor
   - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®Consistency Level

3. **ç›´è¿‘ã®éšœå®³äº‹ä¾‹**
   - æœ€è¿‘ç™ºç”Ÿã—ãŸCassandraé–¢é€£ã®éšœå®³å†…å®¹
   - æœ€ã‚‚ç—›ã„å•é¡Œã¯ä½•ã‹

4. **ã‚³ãƒ¼ãƒ‰ã®é…ç½®**
   - Cassandraã‚¢ã‚¯ã‚»ã‚¹ã‚³ãƒ¼ãƒ‰ã¯DAOå±¤ã«é›†ç´„ã•ã‚Œã¦ã„ã‚‹ã‹
   - æ•£åœ¨ã—ã¦ã„ã‚‹ã‹

### ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ææ¡ˆ

ã¾ãšã¯**1é€±é–“**ã§ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œæˆã—ã€åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¾ã™:

**ã‚¹ã‚³ãƒ¼ãƒ—**:
- Javaãƒ•ã‚¡ã‚¤ãƒ« 10-20å€‹
- ALLOW FILTERINGæ¤œå‡º
- Partition Keyæœªä½¿ç”¨æ¤œå‡º
- ç°¡æ˜“ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›

**ãƒ‡ãƒ¢å¯èƒ½ãªæˆæœç‰©**:
- å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰å•é¡Œã‚’æ¤œå‡º
- HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
- ä¿®æ­£æ¨å¥¨äº‹é …ã®æç¤º

ã“ã®æ–¹å‘æ€§ã§ã‚ˆã‚ã—ã„ã§ã—ã‚‡ã†ã‹? è©³ç´°ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚

---

**æœ¬ä»•æ§˜æ›¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v1.2 (Cassandra Specialized)  
**æœ€çµ‚æ›´æ–°æ—¥**: 2025å¹´10æœˆ26æ—¥
